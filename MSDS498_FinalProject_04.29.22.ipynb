{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSDS 498 - Final Project Notebook: Jay Vaidya & Ruchi Kumar\n",
    "# Project Working Title: Corporate Earnings Call Sentiment Analysis & Time-Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayvaidya/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Import initial packages to be used in the project\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from collections import Counter\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import wikipedia\n",
    "import gensim\n",
    "import itertools\n",
    "import re\n",
    "import wget\n",
    "import pprint as pp\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jayvaidya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jayvaidya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/jayvaidya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download: 1) 'punkt' an unsupervised sentence tokenizer; 2) stopwords; and 3) wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: RUCHI - You can ignore this cell, it is specific to my machine which needs to enable memory growth to permit both GPUs to be utilized\n",
    "# Set memory growth to true to enable proper functioning of GPUs\n",
    "for device in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayvaidya/Documents/MSDS498\n"
     ]
    }
   ],
   "source": [
    "# Set the current working directory\n",
    "%cd \"/home/jayvaidya/Documents/MSDS498\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the serialized dataset to be used in this analysis \n",
    "# Use pandas 'read_pickle' to decompress the file and generate a dataframe\n",
    "data = pd.read_pickle('datasets/audited_transcript_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this stage, we will begin our exploration of the dataset in an attempt to understanding the underlying information contained therein, as well as the properties of the variables we will be using in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>companyid</th>\n",
       "      <th>keydevid</th>\n",
       "      <th>headline</th>\n",
       "      <th>...</th>\n",
       "      <th>sectordescription</th>\n",
       "      <th>subsectorcode</th>\n",
       "      <th>subsectordescription</th>\n",
       "      <th>industrycode</th>\n",
       "      <th>industrydescription</th>\n",
       "      <th>region</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>munistate</th>\n",
       "      <th>analyst</th>\n",
       "      <th>naic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>50297028</td>\n",
       "      <td>1239202</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>329610</td>\n",
       "      <td>What I would say is that from what we see so f...</td>\n",
       "      <td>29900834.0</td>\n",
       "      <td>429604289.0</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>50297028</td>\n",
       "      <td>1239202</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>329610</td>\n",
       "      <td>What I would say is that from what we see so f...</td>\n",
       "      <td>28062.0</td>\n",
       "      <td>429604289.0</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>54816745</td>\n",
       "      <td>1372076</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>257993</td>\n",
       "      <td>Look, I see them in the same ballpark, just ov...</td>\n",
       "      <td>177698.0</td>\n",
       "      <td>545664372.0</td>\n",
       "      <td>Halliburton Company, 2017 Earnings Call, Jan 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>CDK</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>691</td>\n",
       "      <td>78797340</td>\n",
       "      <td>2014164</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>150196</td>\n",
       "      <td>Doug, do you want to…</td>\n",
       "      <td>318561.0</td>\n",
       "      <td>668928990.0</td>\n",
       "      <td>Credit Acceptance Corporation, Q1 2020 Earning...</td>\n",
       "      <td>...</td>\n",
       "      <td>Financial Institutions</td>\n",
       "      <td>FINCOMP</td>\n",
       "      <td>Finance Companies</td>\n",
       "      <td>FINANCECO</td>\n",
       "      <td>Finance Company</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>MI</td>\n",
       "      <td>DIM0003</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>759</td>\n",
       "      <td>76655438</td>\n",
       "      <td>1952553</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>116006</td>\n",
       "      <td>Yes, it's 1.2.</td>\n",
       "      <td>322121.0</td>\n",
       "      <td>261993510.0</td>\n",
       "      <td>The Scotts Miracle-Gro Company, Q2 2014 Earnin...</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>5</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>OH</td>\n",
       "      <td>KAH0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  transcriptcomponentid  transcriptid  componentorder  \\\n",
       "27      27               50297028       1239202              66   \n",
       "28      28               50297028       1239202              66   \n",
       "571    571               54816745       1372076              44   \n",
       "691    691               78797340       2014164             104   \n",
       "759    759               76655438       1952553             119   \n",
       "\n",
       "     transcriptcomponenttypeid  transcriptpersonid  \\\n",
       "27                           4              329610   \n",
       "28                           4              329610   \n",
       "571                          4              257993   \n",
       "691                          4              150196   \n",
       "759                          4              116006   \n",
       "\n",
       "                                         componenttext   companyid  \\\n",
       "27   What I would say is that from what we see so f...  29900834.0   \n",
       "28   What I would say is that from what we see so f...     28062.0   \n",
       "571  Look, I see them in the same ballpark, just ov...    177698.0   \n",
       "691                              Doug, do you want to…    318561.0   \n",
       "759                                     Yes, it's 1.2.    322121.0   \n",
       "\n",
       "        keydevid                                           headline  ...  \\\n",
       "27   429604289.0  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...  ...   \n",
       "28   429604289.0  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...  ...   \n",
       "571  545664372.0  Halliburton Company, 2017 Earnings Call, Jan 2...  ...   \n",
       "691  668928990.0  Credit Acceptance Corporation, Q1 2020 Earning...  ...   \n",
       "759  261993510.0  The Scotts Miracle-Gro Company, Q2 2014 Earnin...  ...   \n",
       "\n",
       "          sectordescription  subsectorcode  subsectordescription industrycode  \\\n",
       "27               Corporates           CORP           Industrials            8   \n",
       "28               Corporates           CORP           Industrials            8   \n",
       "571              Corporates           CORP           Industrials           20   \n",
       "691  Financial Institutions        FINCOMP     Finance Companies    FINANCECO   \n",
       "759              Corporates           CORP           Industrials            5   \n",
       "\n",
       "    industrydescription  region countrycode  munistate  analyst  naic  \n",
       "27          Health Care     USA         USA         CA     None  None  \n",
       "28          Health Care     USA         USA         CA     None  None  \n",
       "571              Energy     USA         USA         TX      CDK  None  \n",
       "691     Finance Company     USA         USA         MI  DIM0003  None  \n",
       "759           Chemicals     USA         USA         OH  KAH0002  None  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the head of the imported dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>companyid</th>\n",
       "      <th>keydevid</th>\n",
       "      <th>headline</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>...</th>\n",
       "      <th>sectordescription</th>\n",
       "      <th>subsectorcode</th>\n",
       "      <th>subsectordescription</th>\n",
       "      <th>industrycode</th>\n",
       "      <th>industrydescription</th>\n",
       "      <th>region</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>munistate</th>\n",
       "      <th>analyst</th>\n",
       "      <th>naic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50297028</td>\n",
       "      <td>1239202</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>329610</td>\n",
       "      <td>What I would say is that from what we see so f...</td>\n",
       "      <td>29900834.0</td>\n",
       "      <td>4.296043e+08</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50297028</td>\n",
       "      <td>1239202</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>329610</td>\n",
       "      <td>What I would say is that from what we see so f...</td>\n",
       "      <td>28062.0</td>\n",
       "      <td>4.296043e+08</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54816745</td>\n",
       "      <td>1372076</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>257993</td>\n",
       "      <td>Look, I see them in the same ballpark, just ov...</td>\n",
       "      <td>177698.0</td>\n",
       "      <td>5.456644e+08</td>\n",
       "      <td>Halliburton Company, 2017 Earnings Call, Jan 2...</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>CDK</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78797340</td>\n",
       "      <td>2014164</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>150196</td>\n",
       "      <td>Doug, do you want to…</td>\n",
       "      <td>318561.0</td>\n",
       "      <td>6.689290e+08</td>\n",
       "      <td>Credit Acceptance Corporation, Q1 2020 Earning...</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>...</td>\n",
       "      <td>Financial Institutions</td>\n",
       "      <td>FINCOMP</td>\n",
       "      <td>Finance Companies</td>\n",
       "      <td>FINANCECO</td>\n",
       "      <td>Finance Company</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>MI</td>\n",
       "      <td>DIM0003</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76655438</td>\n",
       "      <td>1952553</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>116006</td>\n",
       "      <td>Yes, it's 1.2.</td>\n",
       "      <td>322121.0</td>\n",
       "      <td>2.619935e+08</td>\n",
       "      <td>The Scotts Miracle-Gro Company, Q2 2014 Earnin...</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>5</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>OH</td>\n",
       "      <td>KAH0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178428</th>\n",
       "      <td>50297000</td>\n",
       "      <td>1239202</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>325590</td>\n",
       "      <td>Following up on what we said, last quarter, we...</td>\n",
       "      <td>28062.0</td>\n",
       "      <td>4.296043e+08</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178429</th>\n",
       "      <td>50245816</td>\n",
       "      <td>1235781</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>283626</td>\n",
       "      <td>Yes, which is traditional standing data center...</td>\n",
       "      <td>138672527.0</td>\n",
       "      <td>4.265464e+08</td>\n",
       "      <td>MACOM Technology Solutions Holdings, Inc., Q2 ...</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>MA</td>\n",
       "      <td>EJO0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178430</th>\n",
       "      <td>93263878</td>\n",
       "      <td>2460657</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>So as you know, it's a very good question beca...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178431</th>\n",
       "      <td>93263880</td>\n",
       "      <td>2460657</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Yes. Anytime. Absolutely. Appreciate it.</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178432</th>\n",
       "      <td>93263882</td>\n",
       "      <td>2460657</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Thank you, operator. We are very optimistic ab...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2178433 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transcriptcomponentid  transcriptid  componentorder  \\\n",
       "0                     50297028       1239202              66   \n",
       "1                     50297028       1239202              66   \n",
       "2                     54816745       1372076              44   \n",
       "3                     78797340       2014164             104   \n",
       "4                     76655438       1952553             119   \n",
       "...                        ...           ...             ...   \n",
       "2178428               50297000       1239202              38   \n",
       "2178429               50245816       1235781              56   \n",
       "2178430               93263878       2460657              11   \n",
       "2178431               93263880       2460657              13   \n",
       "2178432               93263882       2460657              15   \n",
       "\n",
       "         transcriptcomponenttypeid  transcriptpersonid  \\\n",
       "0                                4              329610   \n",
       "1                                4              329610   \n",
       "2                                4              257993   \n",
       "3                                4              150196   \n",
       "4                                4              116006   \n",
       "...                            ...                 ...   \n",
       "2178428                          4              325590   \n",
       "2178429                          4              283626   \n",
       "2178430                          4              452213   \n",
       "2178431                          4              452213   \n",
       "2178432                          4              452213   \n",
       "\n",
       "                                             componenttext    companyid  \\\n",
       "0        What I would say is that from what we see so f...   29900834.0   \n",
       "1        What I would say is that from what we see so f...      28062.0   \n",
       "2        Look, I see them in the same ballpark, just ov...     177698.0   \n",
       "3                                    Doug, do you want to…     318561.0   \n",
       "4                                           Yes, it's 1.2.     322121.0   \n",
       "...                                                    ...          ...   \n",
       "2178428  Following up on what we said, last quarter, we...      28062.0   \n",
       "2178429  Yes, which is traditional standing data center...  138672527.0   \n",
       "2178430  So as you know, it's a very good question beca...  561218649.0   \n",
       "2178431           Yes. Anytime. Absolutely. Appreciate it.  561218649.0   \n",
       "2178432  Thank you, operator. We are very optimistic ab...  561218649.0   \n",
       "\n",
       "             keydevid                                           headline  \\\n",
       "0        4.296043e+08  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...   \n",
       "1        4.296043e+08  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...   \n",
       "2        5.456644e+08  Halliburton Company, 2017 Earnings Call, Jan 2...   \n",
       "3        6.689290e+08  Credit Acceptance Corporation, Q1 2020 Earning...   \n",
       "4        2.619935e+08  The Scotts Miracle-Gro Company, Q2 2014 Earnin...   \n",
       "...               ...                                                ...   \n",
       "2178428  4.296043e+08  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...   \n",
       "2178429  4.265464e+08  MACOM Technology Solutions Holdings, Inc., Q2 ...   \n",
       "2178430  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "2178431  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "2178432  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "\n",
       "        mostimportantdateutc  ...       sectordescription  subsectorcode  \\\n",
       "0                 2017-05-10  ...              Corporates           CORP   \n",
       "1                 2017-05-10  ...              Corporates           CORP   \n",
       "2                 2018-01-22  ...              Corporates           CORP   \n",
       "3                 2020-05-27  ...  Financial Institutions        FINCOMP   \n",
       "4                 2014-05-05  ...              Corporates           CORP   \n",
       "...                      ...  ...                     ...            ...   \n",
       "2178428           2017-05-10  ...              Corporates           CORP   \n",
       "2178429           2017-04-25  ...              Corporates           CORP   \n",
       "2178430           2021-12-10  ...              Corporates           CORP   \n",
       "2178431           2021-12-10  ...              Corporates           CORP   \n",
       "2178432           2021-12-10  ...              Corporates           CORP   \n",
       "\n",
       "        subsectordescription industrycode     industrydescription region  \\\n",
       "0                Industrials            8             Health Care    USA   \n",
       "1                Industrials            8             Health Care    USA   \n",
       "2                Industrials           20                  Energy    USA   \n",
       "3          Finance Companies    FINANCECO         Finance Company    USA   \n",
       "4                Industrials            5               Chemicals    USA   \n",
       "...                      ...          ...                     ...    ...   \n",
       "2178428          Industrials            8             Health Care    USA   \n",
       "2178429          Industrials            9  Information Technology    USA   \n",
       "2178430          Industrials           20                  Energy    USA   \n",
       "2178431          Industrials           20                  Energy    USA   \n",
       "2178432          Industrials           20                  Energy    USA   \n",
       "\n",
       "         countrycode munistate  analyst  naic  \n",
       "0                USA        CA     None  None  \n",
       "1                USA        CA     None  None  \n",
       "2                USA        TX      CDK  None  \n",
       "3                USA        MI  DIM0003  None  \n",
       "4                USA        OH  KAH0002  None  \n",
       "...              ...       ...      ...   ...  \n",
       "2178428          USA        CA     None  None  \n",
       "2178429          USA        MA  EJO0001  None  \n",
       "2178430          USA        TX  PAO0002  None  \n",
       "2178431          USA        TX  PAO0002  None  \n",
       "2178432          USA        TX  PAO0002  None  \n",
       "\n",
       "[2178433 rows x 63 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the duplicate 'index' column\n",
    "data = data.drop(columns=['index'])\n",
    "# Reindex the data so it can be better manipulated\n",
    "data.reset_index(inplace=True)\n",
    "data = data.drop(columns=['index'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>companyid</th>\n",
       "      <th>keydevid</th>\n",
       "      <th>headline</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>...</th>\n",
       "      <th>sectordescription</th>\n",
       "      <th>subsectorcode</th>\n",
       "      <th>subsectordescription</th>\n",
       "      <th>industrycode</th>\n",
       "      <th>industrydescription</th>\n",
       "      <th>region</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>munistate</th>\n",
       "      <th>analyst</th>\n",
       "      <th>naic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50297028</td>\n",
       "      <td>1239202</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>329610</td>\n",
       "      <td>What I would say is that from what we see so f...</td>\n",
       "      <td>29900834.0</td>\n",
       "      <td>4.296043e+08</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54816745</td>\n",
       "      <td>1372076</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>257993</td>\n",
       "      <td>Look, I see them in the same ballpark, just ov...</td>\n",
       "      <td>177698.0</td>\n",
       "      <td>5.456644e+08</td>\n",
       "      <td>Halliburton Company, 2017 Earnings Call, Jan 2...</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>CDK</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78797340</td>\n",
       "      <td>2014164</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>150196</td>\n",
       "      <td>Doug, do you want to…</td>\n",
       "      <td>318561.0</td>\n",
       "      <td>6.689290e+08</td>\n",
       "      <td>Credit Acceptance Corporation, Q1 2020 Earning...</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>...</td>\n",
       "      <td>Financial Institutions</td>\n",
       "      <td>FINCOMP</td>\n",
       "      <td>Finance Companies</td>\n",
       "      <td>FINANCECO</td>\n",
       "      <td>Finance Company</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>MI</td>\n",
       "      <td>DIM0003</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76655438</td>\n",
       "      <td>1952553</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>116006</td>\n",
       "      <td>Yes, it's 1.2.</td>\n",
       "      <td>322121.0</td>\n",
       "      <td>2.619935e+08</td>\n",
       "      <td>The Scotts Miracle-Gro Company, Q2 2014 Earnin...</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>5</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>OH</td>\n",
       "      <td>KAH0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75885863</td>\n",
       "      <td>1930288</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>151107</td>\n",
       "      <td>Nick?</td>\n",
       "      <td>256689.0</td>\n",
       "      <td>6.560668e+08</td>\n",
       "      <td>Vector Group Ltd., Q4 2019 Earnings Call, Feb ...</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>6</td>\n",
       "      <td>Consumer Products</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>FL</td>\n",
       "      <td>PJ4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178427</th>\n",
       "      <td>50297000</td>\n",
       "      <td>1239202</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>325590</td>\n",
       "      <td>Following up on what we said, last quarter, we...</td>\n",
       "      <td>29900834.0</td>\n",
       "      <td>4.296043e+08</td>\n",
       "      <td>DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178429</th>\n",
       "      <td>50245816</td>\n",
       "      <td>1235781</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>283626</td>\n",
       "      <td>Yes, which is traditional standing data center...</td>\n",
       "      <td>138672527.0</td>\n",
       "      <td>4.265464e+08</td>\n",
       "      <td>MACOM Technology Solutions Holdings, Inc., Q2 ...</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>MA</td>\n",
       "      <td>EJO0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178430</th>\n",
       "      <td>93263878</td>\n",
       "      <td>2460657</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>So as you know, it's a very good question beca...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178431</th>\n",
       "      <td>93263880</td>\n",
       "      <td>2460657</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Yes. Anytime. Absolutely. Appreciate it.</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178432</th>\n",
       "      <td>93263882</td>\n",
       "      <td>2460657</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Thank you, operator. We are very optimistic ab...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1539725 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transcriptcomponentid  transcriptid  componentorder  \\\n",
       "0                     50297028       1239202              66   \n",
       "2                     54816745       1372076              44   \n",
       "3                     78797340       2014164             104   \n",
       "4                     76655438       1952553             119   \n",
       "5                     75885863       1930288              45   \n",
       "...                        ...           ...             ...   \n",
       "2178427               50297000       1239202              38   \n",
       "2178429               50245816       1235781              56   \n",
       "2178430               93263878       2460657              11   \n",
       "2178431               93263880       2460657              13   \n",
       "2178432               93263882       2460657              15   \n",
       "\n",
       "         transcriptcomponenttypeid  transcriptpersonid  \\\n",
       "0                                4              329610   \n",
       "2                                4              257993   \n",
       "3                                4              150196   \n",
       "4                                4              116006   \n",
       "5                                4              151107   \n",
       "...                            ...                 ...   \n",
       "2178427                          4              325590   \n",
       "2178429                          4              283626   \n",
       "2178430                          4              452213   \n",
       "2178431                          4              452213   \n",
       "2178432                          4              452213   \n",
       "\n",
       "                                             componenttext    companyid  \\\n",
       "0        What I would say is that from what we see so f...   29900834.0   \n",
       "2        Look, I see them in the same ballpark, just ov...     177698.0   \n",
       "3                                    Doug, do you want to…     318561.0   \n",
       "4                                           Yes, it's 1.2.     322121.0   \n",
       "5                                                    Nick?     256689.0   \n",
       "...                                                    ...          ...   \n",
       "2178427  Following up on what we said, last quarter, we...   29900834.0   \n",
       "2178429  Yes, which is traditional standing data center...  138672527.0   \n",
       "2178430  So as you know, it's a very good question beca...  561218649.0   \n",
       "2178431           Yes. Anytime. Absolutely. Appreciate it.  561218649.0   \n",
       "2178432  Thank you, operator. We are very optimistic ab...  561218649.0   \n",
       "\n",
       "             keydevid                                           headline  \\\n",
       "0        4.296043e+08  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...   \n",
       "2        5.456644e+08  Halliburton Company, 2017 Earnings Call, Jan 2...   \n",
       "3        6.689290e+08  Credit Acceptance Corporation, Q1 2020 Earning...   \n",
       "4        2.619935e+08  The Scotts Miracle-Gro Company, Q2 2014 Earnin...   \n",
       "5        6.560668e+08  Vector Group Ltd., Q4 2019 Earnings Call, Feb ...   \n",
       "...               ...                                                ...   \n",
       "2178427  4.296043e+08  DJO Global Inc., DJO Finance LLC, Q1 2017 Earn...   \n",
       "2178429  4.265464e+08  MACOM Technology Solutions Holdings, Inc., Q2 ...   \n",
       "2178430  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "2178431  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "2178432  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "\n",
       "        mostimportantdateutc  ...       sectordescription  subsectorcode  \\\n",
       "0                 2017-05-10  ...              Corporates           CORP   \n",
       "2                 2018-01-22  ...              Corporates           CORP   \n",
       "3                 2020-05-27  ...  Financial Institutions        FINCOMP   \n",
       "4                 2014-05-05  ...              Corporates           CORP   \n",
       "5                 2020-02-28  ...              Corporates           CORP   \n",
       "...                      ...  ...                     ...            ...   \n",
       "2178427           2017-05-10  ...              Corporates           CORP   \n",
       "2178429           2017-04-25  ...              Corporates           CORP   \n",
       "2178430           2021-12-10  ...              Corporates           CORP   \n",
       "2178431           2021-12-10  ...              Corporates           CORP   \n",
       "2178432           2021-12-10  ...              Corporates           CORP   \n",
       "\n",
       "        subsectordescription industrycode     industrydescription region  \\\n",
       "0                Industrials            8             Health Care    USA   \n",
       "2                Industrials           20                  Energy    USA   \n",
       "3          Finance Companies    FINANCECO         Finance Company    USA   \n",
       "4                Industrials            5               Chemicals    USA   \n",
       "5                Industrials            6       Consumer Products    USA   \n",
       "...                      ...          ...                     ...    ...   \n",
       "2178427          Industrials            8             Health Care    USA   \n",
       "2178429          Industrials            9  Information Technology    USA   \n",
       "2178430          Industrials           20                  Energy    USA   \n",
       "2178431          Industrials           20                  Energy    USA   \n",
       "2178432          Industrials           20                  Energy    USA   \n",
       "\n",
       "         countrycode munistate  analyst  naic  \n",
       "0                USA        CA     None  None  \n",
       "2                USA        TX      CDK  None  \n",
       "3                USA        MI  DIM0003  None  \n",
       "4                USA        OH  KAH0002  None  \n",
       "5                USA        FL      PJ4  None  \n",
       "...              ...       ...      ...   ...  \n",
       "2178427          USA        CA     None  None  \n",
       "2178429          USA        MA  EJO0001  None  \n",
       "2178430          USA        TX  PAO0002  None  \n",
       "2178431          USA        TX  PAO0002  None  \n",
       "2178432          USA        TX  PAO0002  None  \n",
       "\n",
       "[1539725 rows x 63 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the first two entries, it appears as though there are some duplicate entries where the 'transcriptid', 'componentorder' and \n",
    "# 'componenttext' match, but the 'companyid' does not. This is an issue. In order to remove duplicates, let's use the 'drop_duplicates' function\n",
    "# based on the column subsets just mentioned (excluding companyid)\n",
    "\n",
    "data_no_dup = data.drop_duplicates(subset=['transcriptid', 'componentorder', 'componenttext'], keep='first')\n",
    "data_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: In looking at the number of rows left in the non-duplicate dataset, it appears as though approximately 600,000 duplicate \n",
    "# datapoints have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcriptcomponentid         int64\n",
       "transcriptid                  int64\n",
       "componentorder                int64\n",
       "transcriptcomponenttypeid     int64\n",
       "transcriptpersonid            int64\n",
       "                              ...  \n",
       "region                       object\n",
       "countrycode                  object\n",
       "munistate                    object\n",
       "analyst                      object\n",
       "naic                         object\n",
       "Length: 63, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data types present in the dataframe\n",
    "data_no_dup.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data rows: 1539725\n",
      "The total number of unique transcripts in the dataset: 54247\n",
      "The total number of unique companies in the dataset: 2304\n",
      "The total number of unique industries in the dataset: 49\n"
     ]
    }
   ],
   "source": [
    "# Determine some of the unique properties of the dataset\n",
    "print('The total number of data rows:', len(data_no_dup))\n",
    "print('The total number of unique transcripts in the dataset:', len(data_no_dup['transcriptid'].unique()))\n",
    "print('The total number of unique companies in the dataset:', len(data_no_dup['companyid'].unique()))\n",
    "print('The total number of unique industries in the dataset:', len(data_no_dup['industrydescription'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataset, first by date of transcript generation, then by transcript id and finally by component order\n",
    "data_no_dup = data_no_dup.sort_values(by=['mostimportantdateutc', 'transcriptid', 'componentorder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>companyid</th>\n",
       "      <th>keydevid</th>\n",
       "      <th>headline</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>...</th>\n",
       "      <th>sectordescription</th>\n",
       "      <th>subsectorcode</th>\n",
       "      <th>subsectordescription</th>\n",
       "      <th>industrycode</th>\n",
       "      <th>industrydescription</th>\n",
       "      <th>region</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>munistate</th>\n",
       "      <th>analyst</th>\n",
       "      <th>naic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70732045</td>\n",
       "      <td>1806760</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Yes Toni, for your first question you are quit...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70732048</td>\n",
       "      <td>1806760</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Yeah let me first startup let say we are prett...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70732051</td>\n",
       "      <td>1806760</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Well first of all I will let start very good q...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70732054</td>\n",
       "      <td>1806760</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Well let’s say let’s look at this way as we fi...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70732057</td>\n",
       "      <td>1806760</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Yeah, that’s a good question. First of all as ...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539720</th>\n",
       "      <td>93263873</td>\n",
       "      <td>2460657</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>John, are you still there? Did you drop? We lo...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539721</th>\n",
       "      <td>93263876</td>\n",
       "      <td>2460657</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Yes. Good morning. We've got you, John.</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539722</th>\n",
       "      <td>93263878</td>\n",
       "      <td>2460657</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>So as you know, it's a very good question beca...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539723</th>\n",
       "      <td>93263880</td>\n",
       "      <td>2460657</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Yes. Anytime. Absolutely. Appreciate it.</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539724</th>\n",
       "      <td>93263882</td>\n",
       "      <td>2460657</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Thank you, operator. We are very optimistic ab...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1539725 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transcriptcomponentid  transcriptid  componentorder  \\\n",
       "0                     70732045       1806760               5   \n",
       "1                     70732048       1806760               8   \n",
       "2                     70732051       1806760              11   \n",
       "3                     70732054       1806760              14   \n",
       "4                     70732057       1806760              17   \n",
       "...                        ...           ...             ...   \n",
       "1539720               93263873       2460657               6   \n",
       "1539721               93263876       2460657               9   \n",
       "1539722               93263878       2460657              11   \n",
       "1539723               93263880       2460657              13   \n",
       "1539724               93263882       2460657              15   \n",
       "\n",
       "         transcriptcomponenttypeid  transcriptpersonid  \\\n",
       "0                                4                8971   \n",
       "1                                4                8971   \n",
       "2                                4                8971   \n",
       "3                                4                8971   \n",
       "4                                4                8971   \n",
       "...                            ...                 ...   \n",
       "1539720                          4              452213   \n",
       "1539721                          4              452213   \n",
       "1539722                          4              452213   \n",
       "1539723                          4              452213   \n",
       "1539724                          4              452213   \n",
       "\n",
       "                                             componenttext    companyid  \\\n",
       "0        Yes Toni, for your first question you are quit...     112350.0   \n",
       "1        Yeah let me first startup let say we are prett...     112350.0   \n",
       "2        Well first of all I will let start very good q...     112350.0   \n",
       "3        Well let’s say let’s look at this way as we fi...     112350.0   \n",
       "4        Yeah, that’s a good question. First of all as ...     112350.0   \n",
       "...                                                    ...          ...   \n",
       "1539720  John, are you still there? Did you drop? We lo...  561218649.0   \n",
       "1539721            Yes. Good morning. We've got you, John.  561218649.0   \n",
       "1539722  So as you know, it's a very good question beca...  561218649.0   \n",
       "1539723           Yes. Anytime. Absolutely. Appreciate it.  561218649.0   \n",
       "1539724  Thank you, operator. We are very optimistic ab...  561218649.0   \n",
       "\n",
       "             keydevid                                           headline  \\\n",
       "0        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "1        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "2        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "3        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "4        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "...               ...                                                ...   \n",
       "1539720  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "1539721  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "1539722  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "1539723  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "1539724  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "\n",
       "        mostimportantdateutc  ...  sectordescription  subsectorcode  \\\n",
       "0                 2006-01-17  ...         Corporates           CORP   \n",
       "1                 2006-01-17  ...         Corporates           CORP   \n",
       "2                 2006-01-17  ...         Corporates           CORP   \n",
       "3                 2006-01-17  ...         Corporates           CORP   \n",
       "4                 2006-01-17  ...         Corporates           CORP   \n",
       "...                      ...  ...                ...            ...   \n",
       "1539720           2021-12-10  ...         Corporates           CORP   \n",
       "1539721           2021-12-10  ...         Corporates           CORP   \n",
       "1539722           2021-12-10  ...         Corporates           CORP   \n",
       "1539723           2021-12-10  ...         Corporates           CORP   \n",
       "1539724           2021-12-10  ...         Corporates           CORP   \n",
       "\n",
       "        subsectordescription industrycode     industrydescription region  \\\n",
       "0                Industrials            9  Information Technology    USA   \n",
       "1                Industrials            9  Information Technology    USA   \n",
       "2                Industrials            9  Information Technology    USA   \n",
       "3                Industrials            9  Information Technology    USA   \n",
       "4                Industrials            9  Information Technology    USA   \n",
       "...                      ...          ...                     ...    ...   \n",
       "1539720          Industrials           20                  Energy    USA   \n",
       "1539721          Industrials           20                  Energy    USA   \n",
       "1539722          Industrials           20                  Energy    USA   \n",
       "1539723          Industrials           20                  Energy    USA   \n",
       "1539724          Industrials           20                  Energy    USA   \n",
       "\n",
       "         countrycode munistate  analyst  naic  \n",
       "0                USA        NY      DDT  None  \n",
       "1                USA        NY      DDT  None  \n",
       "2                USA        NY      DDT  None  \n",
       "3                USA        NY      DDT  None  \n",
       "4                USA        NY      DDT  None  \n",
       "...              ...       ...      ...   ...  \n",
       "1539720          USA        TX  PAO0002  None  \n",
       "1539721          USA        TX  PAO0002  None  \n",
       "1539722          USA        TX  PAO0002  None  \n",
       "1539723          USA        TX  PAO0002  None  \n",
       "1539724          USA        TX  PAO0002  None  \n",
       "\n",
       "[1539725 rows x 63 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, once again, reset the index\n",
    "data_no_dup.reset_index(inplace=True)\n",
    "data_no_dup = data_no_dup.drop(columns=['index'])\n",
    "data_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first datapoint date available in the dataset is 2006-01-17\n",
      "The last datapoint date available in the dataset is 2021-12-10\n"
     ]
    }
   ],
   "source": [
    "print('The first datapoint date available in the dataset is',data_no_dup['mostimportantdateutc'][0])\n",
    "print('The last datapoint date available in the dataset is',data_no_dup['mostimportantdateutc'].values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for assistance in EDA analysis: https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's now plot the length of the 'componenttext' variable across the dataset by producing a histogram\n",
    "# NOTE: The length method is returning the number of characters in a given entry, not the number of words and punctuations, or the like\n",
    "\n",
    "comp_len = []\n",
    "for i in range(len(data_no_dup)):\n",
    "    current_len = len(data_no_dup['componenttext'][i])\n",
    "    comp_len.append(current_len)\n",
    "\n",
    "pd.DataFrame(comp_len).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum component text length: 20912 tokens\n",
      "Minimum component text length: 2 tokens\n",
      "Median component text length: 458 tokens\n"
     ]
    }
   ],
   "source": [
    "print('Maximum component text length:', max(comp_len), 'tokens')\n",
    "print('Minimum component text length:', min(comp_len), 'tokens')\n",
    "print('Median component text length:', statistics.median(comp_len), 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's determine the average word length in each transcript\n",
    "data_no_dup['componenttext'].str.split().\\\n",
    "   apply(lambda x : [len(i) for i in x]). \\\n",
    "   map(lambda x: np.mean(x)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to understand the text data present in the dataset, let's remove stopwords and look at the remaining word corpus\n",
    "# Let's download the stopwords from the NLTK package and generate an object containing stop words\n",
    "\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the corpus of words\n",
    "corpus=[]\n",
    "new= data_no_dup['componenttext'].str.split()\n",
    "new=new.values.tolist()\n",
    "corpus=[word for i in new for word in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the most common stop words used in the corpus by using a dict to count the number of occurrences of each stop word\n",
    "from collections import defaultdict\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAP3klEQVR4nO3dfYxldX3H8fenCwosVKqMBkVcqoixGh+YWhFLVnwIFqttSivEh2JsN8YH0PpEo1HbtAmpjbVNtHaklmpxrVCwRgNKouuuCMgsD7LLgrGAClUYVJSlVJB++8c9A8Nwl7nj3nP3tzvvV3IzZ+45c7/fe2buZ37zm3PuSVUhSWrXr+zqBiRJD82glqTGGdSS1DiDWpIaZ1BLUuMMaklqXG9BneQTSW5NsmXE7f8oyTVJtib5dF99SdLuJn0dR53kGGA78MmqetoS2x4OfBY4tqp+kuTRVXVrL41J0m6mtxF1VW0EfrzwviRPTHJBks1JNiV5SrfqT4GPVNVPuq81pCWpM+k56hngLVV1JPAO4KPd/U8GnpzkoiSXJDluwn1JUrP2mlShJPsDzwPOTjJ/98MX9HE4sBY4BNiY5OlVdfuk+pOkVk0sqBmM3m+vqmcOWXcTcGlV3QPckOTbDIL7sgn2J0lNmtjUR1X9jEEI/yFABp7Rrf4cg9E0SQ5iMBVy/aR6k6SW9Xl43nrgYuCIJDcleT3wKuD1Sa4CtgKv6Db/EvCjJNcAXwXeWVU/6qs3Sdqd9HZ4niRpPDwzUZIa18s/Ew866KBas2ZNHw8tSXukzZs331ZVU8PW9RLUa9asYXZ2to+HlqQ9UpLv7midUx+S1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDVupKBO8rbuEllbkqxPsk/fjUmSBpYM6iSPA04BprtLaq0CTuy7MUnSwKhnJu4F7JvkHmA/4L/7amjNaV/s66Hvc+Ppx/deQ5LGZckRdVXdDPwt8D3gB8BPq+rLi7dLsi7JbJLZubm58XcqSSvUKFMfv8bgfaMPAx4LrE7y6sXbVdVMVU1X1fTU1ND3FZEk/RJG+Wfii4Abqmquu1TWuQyufShJmoBRgvp7wHOT7JfBVWlfCGzrty1J0rxR5qgvBc4BLgeu7r5mpue+JEmdkY76qKr3A+/vuRdJ0hCemShJjTOoJalxBrUkNc6glqTGGdSS1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjDGpJatwoF7c9IsmVC24/S/LWCfQmSWKEK7xU1XXAMwGSrAJuBs7rty1J0rzlTn28EPivqvpuH81Ikh5suUF9IrC+j0YkScONHNRJHga8HDh7B+vXJZlNMjs3Nzeu/iRpxVvOiPqlwOVVdcuwlVU1U1XTVTU9NTU1nu4kScsK6pNw2kOSJm6koE6yGngxcG6/7UiSFlvy8DyAqroTeFTPvUiShvDMRElqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEGtSQ1zqCWpMYZ1JLUOINakhpnUEtS4wxqSWrcqJfiOjDJOUmuTbItyVF9NyZJGhjpUlzA3wMXVNUJSR4G7NdjT5KkBZYM6iSPAI4BTgaoqruBu/ttS5I0b5Spj8OAOeBfklyR5IzuquQPkGRdktkks3Nzc2NvVJJWqlGCei/g2cA/VtWzgDuB0xZvVFUzVTVdVdNTU1NjblOSVq5Rgvom4KaqurT7/BwGwS1JmoAlg7qqfgh8P8kR3V0vBK7ptStJ0n1GPerjLcBZ3REf1wOv668lSdJCIwV1VV0JTPfbiiRpGM9MlKTGGdSS1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEGtSQ1zqCWpMaNdIWXJDcCdwD3Ar+oKq/2IkkTMuo1EwFeUFW39daJJGkopz4kqXGjjqgL+HKSAv6pqmYWb5BkHbAO4NBDDx1fhxO05rQv9l7jxtOP772GpD3LqCPq51fVs4GXAm9KcsziDapqpqqmq2p6ampqrE1K0ko2UlBX1c3dx1uB84Dn9NmUJOl+SwZ1ktVJDphfBl4CbOm7MUnSwChz1I8Bzksyv/2nq+qCXruSJN1nyaCuquuBZ0ygF0nSEB6eJ0mNM6glqXEGtSQ1zqCWpMYZ1JLUOINakhpnUEtS45bzNqfqkW8IJWlHHFFLUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjRg7qJKuSXJHkC302JEl6oOWMqE8FtvXViCRpuJGCOskhwPHAGf22I0labNQ3Zfow8C7ggB1tkGQdsA7g0EMP3enGNDm+IZTUtiWDOsnLgFuranOStTvarqpmgBmA6enpGleD2rP5S0Ja2ihTH0cDL09yI/AZ4Ngk/9ZrV5Kk+ywZ1FX151V1SFWtAU4EvlJVr+69M0kS4HHUktS8ZV3hpao2ABt66USSNJQjaklqnEEtSY0zqCWpcV6FXCuWx3Brd2FQS7uAvyS0HE59SFLjDGpJapxBLUmNc45aWmGcH9/9OKKWpMYZ1JLUOINakhpnUEtS4wxqSWqcQS1JjTOoJalxSwZ1kn2SfDPJVUm2JvmLSTQmSRoY5YSXnwPHVtX2JHsDX09yflVd0nNvkiRGCOqqKmB79+ne3a36bEqSdL+R5qiTrEpyJXArcGFVXdprV5Kk+4wU1FV1b1U9EzgEeE6Spy3eJsm6JLNJZufm5sbcpiStXMs66qOqbge+Chw3ZN1MVU1X1fTU1NSY2pMkjXLUx1SSA7vlfYEXA9f23JckqTPKUR8HA/+aZBWDYP9sVX2h37YkSfNGOerjW8CzJtCLJGkIz0yUpMYZ1JLUOINakhpnUEtS4wxqSWqcQS1JjTOoJalxBrUkNc6glqTGGdSS1DiDWpIaZ1BLUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxo1yzcTHJ/lqkmuSbE1y6iQakyQNjHLNxF8Ab6+qy5McAGxOcmFVXdNzb5IkRhhRV9UPqurybvkOYBvwuL4bkyQNLGuOOskaBhe6vXTIunVJZpPMzs3Njak9SdIoUx8AJNkf+A/grVX1s8Xrq2oGmAGYnp6usXUoaY+x5rQv9l7jxtOP773GpI00ok6yN4OQPquqzu23JUnSQkuOqJME+GdgW1V9qP+WJGn8dufR/Cgj6qOB1wDHJrmyu/1OL91Ikh5kyRF1VX0dyAR6kSQN4ZmJktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEGtSQ1zqCWpMYZ1JLUOINakhpnUEtS4wxqSWqcQS1JjTOoJalxBrUkNc6glqTGGdSS1LglgzrJJ5LcmmTLJBqSJD3QKCPqM4Hjeu5DkrQDSwZ1VW0EfjyBXiRJQ4xtjjrJuiSzSWbn5ubG9bCStOKNLairaqaqpqtqempqalwPK0krnkd9SFLjDGpJatwoh+etBy4GjkhyU5LX99+WJGneXkttUFUnTaIRSdJwTn1IUuMMaklqnEEtSY0zqCWpcQa1JDXOoJakxhnUktQ4g1qSGmdQS1LjDGpJapxBLUmNM6glqXEGtSQ1zqCWpMYZ1JLUOINakhpnUEtS40YK6iTHJbkuyXeSnNZ3U5Kk+41yzcRVwEeAlwJPBU5K8tS+G5MkDYwyon4O8J2qur6q7gY+A7yi37YkSfNSVQ+9QXICcFxV/Un3+WuA36qqNy/abh2wrvv0COC68bc71EHAbROqZe2VXXtX17f2nl37CVU1NWzFklchH1VVzQAz43q8USWZrarpSde19sqrvavrW3tl1V5olKmPm4HHL/j8kO4+SdIEjBLUlwGHJzksycOAE4HP99uWJGneklMfVfWLJG8GvgSsAj5RVVt772x0E59usfaKrb2r61t7ZdW+z5L/TJQk7VqemShJjTOoJalxzQd1kgOTvLFbXpvkCy300ookpyTZluSsMTzWTu3rJCcneezO9rG7SrJ9zI/3jXE+3u5kJT/3YZoPauBAoJVwPJB2epn3RuDFVfWqMTzWgezc8zsZWLFBPW5V9bxd3cOusjs89yRjOw9lKbtDUJ8OPDHJlcAHgf2TnJPk2iRnJQlAkiOTfC3J5iRfSnJwn70k+WB325Lk6iSv7KHeAyT5s67eliRvTfIx4NeB85O8bQwlRt3X70tyWdfHTAZOAKaBs7r9s+/ONJLknUlO6Zb/LslXuuVju15ekuTiJJcnOTvJ/jtTb0Hdz3U/Q1u7s21Jsj3JXye5KsklSR7T3X9Y18PVSf5qHPUX9bK9+7g2yYZh34u+DdsfE6o7/9wPTrKx+5nakuS3e6i1+HW1JsmWBevfkeQD3fKGJB9OMgucOu5edqiqmr4Ba4At3fJa4KcMTrr5FeBi4PnA3sA3gKluu1cyOIywz17+ALiQwSGLjwG+Bxzc4344ErgaWA3sD2wFngXcCBw0qX3drXvkgq/5FPC73fIGYHpMvTwXOLtb3gR8s/s+vx94N7ARWN2tfzfwvjHVfWT3cV9gC/AooBY8x78B3tstfx54bbf8JmD7mL/n25f6XvR9G7Y/JlR3/rm/HXhPt7wKOGDMdXb0utqyYJt3AB/oljcAH53EPlh42x1G1It9s6puqqr/A65kEC5HAE8DLuxGg+9l8EPdp+cD66vq3qq6Bfga8Js91zuvqu6squ3AucDYRxeLDNvXAC9IcmmSq4Fjgd/oofZm4Mgkvwr8nEE4TTN4zncxeCfHi7rv9x8DTxhT3VOSXAVcwuCM3MOBu4H5+frN3L8fjgbWd8ufGlP9HdnR96Jvw/bHJF0GvK4b0T69qu4Y8+P/Mq+rfx9zD0ua2BzLGP18wfK9DJ5DgK1VddSuaWmP9aB9nWQf4KMMRs7f715A+4y7cFXdk+QGBvPe3wC+BbwAeBJwA3BhVZ00zppJ1gIvAo6qqv9JsoHBc7unuuEU9//M3dfqOHt4CMN+7nv1EPtjYqpqY5JjgOOBM5N8qKo+2XPZA3ngtPDi53xnz/UfZHcYUd8BHLDENtcBU0mOAkiyd5I+RnkLe9kEvDLJqiRTwDEM/jzvyybg95Lsl2Q18PvdfeM0yr6e/6G9rZsXPmGZX78cmxj82bmxW34DcAWD0d3RSZ4EkGR1kiePod4jgJ90ofQUBtMvD+UiBm+pADCOf+a2Zrn7Y+ySPAG4pao+DpwBPHvMJYa9rs4HHp3kUUkeDrxszDWXrfkRdVX9KMlF3eT+XcAtQ7a5u/tn1j8keQSD5/VhBvNNffVyPoNR3lUMRlXvqqofjrPeotqXJzmT+38ZnFFVV4zzf0oj7uvbk3ycwXzlDxn8aTrvTOBjSe5iMAq7aydb2gS8B7i4qu5M8r/ApqqaS3IysL57IcFguuvbO1nvAuANSbYx+OV/yRLbnwp8Osm7gf/cydotWu7+6MNa4J1J7gG2A68d54Pv4HV1WZK/7O67Gbh2nDV/GZ5CLkmN2x2mPiRpRTOoJalxBrUkNc6glqTGGdSS1DiDWpIaZ1BLUuP+H4t6M4UmB4aZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's plot the top stop words to visualize their usage\n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the most commonly occuring non-stop words\n",
    "counter=Counter(corpus)\n",
    "most=counter.most_common()\n",
    "\n",
    "x, y= [], []\n",
    "for word,count in most[:40]:\n",
    "    if (word not in stop):\n",
    "        x.append(word)\n",
    "        y.append(count)\n",
    "        \n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting n-grams\n",
    "def plot_top_ngrams_barchart(text, n=2):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:10]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:10]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top bi-grams\n",
    "plot_top_ngrams_barchart(data_no_dup['componenttext'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top tri-grams\n",
    "plot_top_ngrams_barchart(data_no_dup['componenttext'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a simple function for preprocessing the text in order to undertaking some topic modelling steps. \n",
    "# This is just for the initial EDA portion of our analysis and does not represent the final pre-processing approach we will use in this project\n",
    "\n",
    "def clean_doc(doc): \n",
    "    #split document into individual words\n",
    "    tokens=doc.split()\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 4]\n",
    "    #lowercase all words\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]         \n",
    "    \n",
    "    # NOTE: For now, let's clean the docs without lemmatization or stemming\n",
    "    # Lemmatization\n",
    "    #lem = WordNetLemmatizer()\n",
    "    #tokens = [lem.lemmatize(w) for w in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Generate the corpus using the preprocessing step defined above\n",
    "corpus= [clean_doc(doc) for doc in data_no_dup['componenttext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'question',\n",
       " 'quite',\n",
       " 'current',\n",
       " 'would',\n",
       " 'operational',\n",
       " 'achievement',\n",
       " 'fourth',\n",
       " 'quarter',\n",
       " 'range',\n",
       " 'excluding',\n",
       " 'estate',\n",
       " 'achieved',\n",
       " 'second',\n",
       " 'question',\n",
       " 'thought',\n",
       " 'million',\n",
       " 'spilled',\n",
       " 'million',\n",
       " 'third',\n",
       " 'million',\n",
       " 'fourth',\n",
       " 'consistent',\n",
       " 'earlier',\n",
       " 'think',\n",
       " 'expense',\n",
       " 'saving',\n",
       " 'restructure',\n",
       " 'remains',\n",
       " 'billion',\n",
       " 'million',\n",
       " 'yeartoyear',\n",
       " 'would',\n",
       " 'actions',\n",
       " 'designs',\n",
       " 'drive',\n",
       " 'competitive',\n",
       " 'business',\n",
       " 'especially',\n",
       " 'services',\n",
       " 'longer',\n",
       " 'action',\n",
       " 'competitive',\n",
       " 'structure',\n",
       " 'pricing',\n",
       " 'flexibility',\n",
       " 'allows',\n",
       " 'better',\n",
       " 'manage',\n",
       " 'excluding',\n",
       " 'labor']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first cleaned 'corpus' entry\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting n-grams\n",
    "def plot_top_ngrams_barchart_v2(text, n=2):\n",
    "    stop=set(stopwords.words('english'))\n",
    "\n",
    "    new= [clean_doc(doc) for doc in text]\n",
    "    #new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    def _get_top_ngram(corpus, n=None):\n",
    "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) \n",
    "                      for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:10]\n",
    "\n",
    "    top_n_bigrams=_get_top_ngram(text,n)[:10]\n",
    "    x,y=map(list,zip(*top_n_bigrams))\n",
    "    sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top bi-grams from the cleaned text, this time\n",
    "plot_top_ngrams_barchart_v2(data_no_dup['componenttext'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top bi-grams from the cleaned text, this time\n",
    "plot_top_ngrams_barchart_v2(data_no_dup['componenttext'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gensim Dictionary we will create a mapping of corpora words to intergers\n",
    "dic=gensim.corpora.Dictionary(corpus)\n",
    "\n",
    "# Then, we generate a bow corpus for each document; in 'corpus' each entry, or slice, represents a document or transcript\n",
    "bow_corpus = [dic.doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.045*\"quarter\" + 0.025*\"think\" + 0.018*\"million\" + 0.014*\"going\" + 0.014*\"first\" + 0.014*\"would\" + 0.013*\"little\" + 0.011*\"second\" + 0.010*\"thats\" + 0.009*\"really\"'),\n",
       " (1,\n",
       "  '0.019*\"think\" + 0.018*\"business\" + 0.014*\"really\" + 0.013*\"growth\" + 0.012*\"thats\" + 0.012*\"market\" + 0.011*\"going\" + 0.011*\"customers\" + 0.008*\"product\" + 0.008*\"products\"'),\n",
       " (2,\n",
       "  '0.035*\"think\" + 0.018*\"going\" + 0.013*\"really\" + 0.010*\"thats\" + 0.010*\"would\" + 0.009*\"things\" + 0.009*\"right\" + 0.008*\"theres\" + 0.008*\"people\" + 0.006*\"business\"'),\n",
       " (3,\n",
       "  '0.023*\"think\" + 0.013*\"thats\" + 0.013*\"would\" + 0.012*\"business\" + 0.011*\"going\" + 0.009*\"capital\" + 0.009*\"margin\" + 0.008*\"continue\" + 0.008*\"really\" + 0.007*\"growth\"'),\n",
       " (4,\n",
       "  '0.020*\"think\" + 0.017*\"thats\" + 0.014*\"would\" + 0.014*\"going\" + 0.009*\"really\" + 0.008*\"right\" + 0.006*\"theres\" + 0.005*\"question\" + 0.005*\"point\" + 0.005*\"could\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we perform LDA topic modeling using Gensim\n",
    "# NOTE: for the 'workers' parameter, this needs to be adjusted based on the number of cores available in your CPU; currently I'm using a machine with 24\n",
    "# cores, so I have set workers = 20\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5, \n",
    "                                   id2word = dic,                                    \n",
    "                                   passes = 3,\n",
    "                                   workers = 20)\n",
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Information Technology                146126\n",
       "Holding Company                       122484\n",
       "Property & Real Estate                121406\n",
       "Capital Goods                         108145\n",
       "Energy                                107448\n",
       "Health Care                            94616\n",
       "Retailing                              90454\n",
       "Consumer Products                      80592\n",
       "Media & Entertainment                  54096\n",
       "Transportation                         47712\n",
       "Commercial & Professional Services     45948\n",
       "Chemicals                              45700\n",
       "Automobiles & Components               36114\n",
       "Finance Company                        34048\n",
       "Electric                               29950\n",
       "Aerospace & Defense                    29024\n",
       "Midstream Energy Companies             28940\n",
       "Metals & Mining                        27007\n",
       "Hotels & Gaming                        26250\n",
       "Building Materials                     23690\n",
       "Business and Consumer Services         23260\n",
       "Paper & Forest Products                20252\n",
       "Telecom Services                       16108\n",
       "Multi                                  14969\n",
       "Asset Manager                          14959\n",
       "Refining Companies                     12062\n",
       "Health Insurance                        9368\n",
       "Bank                                    8505\n",
       "Containers & Packaging                  8365\n",
       "Exchanges & Clearing Corporations       6919\n",
       "Gas                                     6247\n",
       "Homebuilding                            5414\n",
       "Insurance Services                      5242\n",
       "Power Companies                         3672\n",
       "Life Insurance                          2917\n",
       "Water                                   2643\n",
       "Property/Casualty Insurance             1991\n",
       "Brokerage Company                       1965\n",
       "Developer                               1426\n",
       "Bank Holding Company                    1320\n",
       "Real Estate Investment Trust             477\n",
       "Government Agencies                      405\n",
       "Bond Insurance                           338\n",
       "Hedge Fund                               222\n",
       "Insurance TPA                            180\n",
       "Liquefied Natural Gas                    160\n",
       "Healthcare Services                       73\n",
       "Energy and Oil & Gas - Other               5\n",
       "Name: industrydescription, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the relative distribution of transcript counts by sector description\n",
    "data_no_dup['industrydescription'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Information Technology                146126\n",
       "Holding Company                       122484\n",
       "Property & Real Estate                121406\n",
       "Capital Goods                         108145\n",
       "Energy                                107448\n",
       "Health Care                            94616\n",
       "Retailing                              90454\n",
       "Consumer Products                      80592\n",
       "Media & Entertainment                  54096\n",
       "Transportation                         47712\n",
       "Commercial & Professional Services     45948\n",
       "Chemicals                              45700\n",
       "Automobiles & Components               36114\n",
       "Finance Company                        34048\n",
       "Electric                               29950\n",
       "Aerospace & Defense                    29024\n",
       "Midstream Energy Companies             28940\n",
       "Metals & Mining                        27007\n",
       "Hotels & Gaming                        26250\n",
       "Building Materials                     23690\n",
       "Name: industrydescription, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the top 20 industries by value counts - we will consider only using these industries for our analysis\n",
    "data_no_dup['industrydescription'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of datapoints in the top 20 industries: 1299750\n",
      "Percentage of data represented by top 20 industries: 0.88\n"
     ]
    }
   ],
   "source": [
    "print('Total number of datapoints in the top 20 industries:', data_no_dup['industrydescription'].value_counts()[:20].sum())\n",
    "print('Percentage of data represented by top 20 industries:', \n",
    "      round(data_no_dup['industrydescription'].value_counts()[:20].sum()/data_no_dup['industrydescription'].value_counts().sum(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Allied Capital Corporation', 'Prospect Capital Corporation',\n",
       "       'American Capital, Ltd.', 'Blackstone Mortgage Trust, Inc.',\n",
       "       'Ares Capital Corporation',\n",
       "       'National Rural Utilities Cooperative Finance Corporation',\n",
       "       'MoneyGram International, Inc.', 'SLR Investment Corp.',\n",
       "       'Ford Motor Credit Company LLC', 'The Western Union Company',\n",
       "       'Jones Lang LaSalle Incorporated', 'Euronet Worldwide, Inc.',\n",
       "       'Credit Acceptance Corporation', 'Ditech Holding Corporation',\n",
       "       'Golub Capital BDC, Inc.', 'Apollo Investment Corporation',\n",
       "       'DFC Global Corp.', 'World Acceptance Corporation', 'iStar Inc.',\n",
       "       'RAIT Financial Trust', 'WEX Inc.', 'PHH Corporation',\n",
       "       'Dynex Capital, Inc.', 'BlackRock Capital Investment Corporation',\n",
       "       'Hercules Capital, Inc.', 'Main Street Capital Corporation',\n",
       "       'Apollo Commercial Real Estate Finance, Inc.',\n",
       "       'Starwood Property Trust, Inc.', 'FLEETCOR Technologies, Inc.',\n",
       "       'Oaktree Specialty Lending Corporation',\n",
       "       'Ocwen Financial Corporation', 'Asset Acceptance Capital Corp.',\n",
       "       'Greenhill & Co., Inc.', 'CBRE Group, Inc.', 'CapitalSource Inc.',\n",
       "       'Hannon Armstrong Sustainable Infrastructure Capital, Inc.',\n",
       "       'New Residential Investment Corp.', 'OneMain Holdings, Inc.',\n",
       "       'Walker & Dunlop, Inc.', 'Navient Corporation',\n",
       "       'Nationstar Mortgage Holdings Inc.', 'Enova International, Inc.',\n",
       "       'FS KKR Capital Corp.', 'Square, Inc.',\n",
       "       'BlackRock TCP Capital Corp.',\n",
       "       'Sixth Street Specialty Lending, Inc.', 'Goldman Sachs BDC, Inc.',\n",
       "       'KKR Real Estate Finance Trust Inc.', 'CURO Group Holdings Corp.',\n",
       "       'Corporate Capital Trust, Inc.', 'CCF Holdings LLC',\n",
       "       'Mr. Cooper Group Inc.', 'Owl Rock Capital Corporation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the unique company names under the 'Finance Company' industry set; because 'banks' are not included in the top 20 industry set, we want\n",
    "# to ensure that a strong group of financial important companies enter our analysis;\n",
    "# A review of the constituents of this subset appears to confirm that a number of large financial intermediaries are present in this list\n",
    "data_no_dup[data_no_dup['industrydescription'] == data_no_dup['industrydescription'].value_counts().index[13]].companyname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In order to test some functions to be developed below, we will create a dummy dataset, mirroring the structure of the real dataset, \n",
    "# comprised of 100 datapoints, or 5 from each of the first 20 categories in the value_counts output above\n",
    "\n",
    "# First, instantiate an empty list that will be populated with the 'dummy data'\n",
    "dummy_data = []\n",
    "\n",
    "# Generate a loop that goes through the top 20 industries, as identified view value counts, and then randomly selects 5 entries from \n",
    "# that industry for addition to the dummy data set\n",
    "for i in range(0, 20):\n",
    "    np.random.seed(1234)\n",
    "    current_elements = np.random.choice(data_no_dup[data_no_dup['industrydescription'] == data_no_dup['industrydescription'].value_counts().index[i]].index.tolist(),\n",
    "                                       size = 5,\n",
    "                                       replace = False)\n",
    "    for j in range(len(current_elements)):\n",
    "        np.random.seed(1234)\n",
    "        current_dummy = data_no_dup[data_no_dup['industrydescription'] == data_no_dup['industrydescription']].loc[current_elements[j]]\n",
    "        dummy_data.append(current_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>companyid</th>\n",
       "      <th>keydevid</th>\n",
       "      <th>headline</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>...</th>\n",
       "      <th>sectordescription</th>\n",
       "      <th>subsectorcode</th>\n",
       "      <th>subsectordescription</th>\n",
       "      <th>industrycode</th>\n",
       "      <th>industrydescription</th>\n",
       "      <th>region</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>munistate</th>\n",
       "      <th>analyst</th>\n",
       "      <th>naic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468814</th>\n",
       "      <td>31993663</td>\n",
       "      <td>725629</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>104551</td>\n",
       "      <td>No, that's -- we're telling you to model that ...</td>\n",
       "      <td>1462309.0</td>\n",
       "      <td>2.744932e+08</td>\n",
       "      <td>Skyworks Solutions Inc., Q4 2014 Earnings Call...</td>\n",
       "      <td>2014-11-06</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>CF0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011148</th>\n",
       "      <td>60215643</td>\n",
       "      <td>1522835</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>324960</td>\n",
       "      <td>Okay, Randy. So looking at SiP, we disclosed t...</td>\n",
       "      <td>124219.0</td>\n",
       "      <td>5.749385e+08</td>\n",
       "      <td>Amkor Technology, Inc., Q2 2018 Earnings Call,...</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>AZ</td>\n",
       "      <td>WER</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17456</th>\n",
       "      <td>6334028</td>\n",
       "      <td>89865</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>93028</td>\n",
       "      <td>I should say, Brendan, to your prior question ...</td>\n",
       "      <td>334962.0</td>\n",
       "      <td>8.493120e+07</td>\n",
       "      <td>ATMI Inc., Q3 2010 Earnings Call, Oct 20, 2010</td>\n",
       "      <td>2010-10-20</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132043</th>\n",
       "      <td>64895264</td>\n",
       "      <td>1646420</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>286913</td>\n",
       "      <td>Yes. Suji, we're expecting both divisions to b...</td>\n",
       "      <td>27307.0</td>\n",
       "      <td>5.984101e+08</td>\n",
       "      <td>Cypress Semiconductor Corporation, Q4 2018 Ear...</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>SES0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536742</th>\n",
       "      <td>92190391</td>\n",
       "      <td>2424326</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>388038</td>\n",
       "      <td>Sure. Thanks, Joe, and thanks for the compleme...</td>\n",
       "      <td>310310.0</td>\n",
       "      <td>1.685657e+09</td>\n",
       "      <td>Unisys Corporation, Q3 2021 Earnings Call, Nov...</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>PA</td>\n",
       "      <td>SHP0006</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352231</th>\n",
       "      <td>74570920</td>\n",
       "      <td>1900832</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>92894</td>\n",
       "      <td>The exact words that Joe used when he was talk...</td>\n",
       "      <td>401541.0</td>\n",
       "      <td>6.519870e+08</td>\n",
       "      <td>Lennox International Inc., Q4 2019 Earnings Ca...</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAG7181</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654168</th>\n",
       "      <td>44544860</td>\n",
       "      <td>1062834</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>120289</td>\n",
       "      <td>Yes, I think if you look at really what we've ...</td>\n",
       "      <td>294338.0</td>\n",
       "      <td>4.038350e+08</td>\n",
       "      <td>Owens Corning, Q3 2016 Earnings Call, Oct 26, ...</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>OH</td>\n",
       "      <td>NIN4616</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393007</th>\n",
       "      <td>76905869</td>\n",
       "      <td>1957524</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>92894</td>\n",
       "      <td>Sure answer is yes to that final piece, which ...</td>\n",
       "      <td>401541.0</td>\n",
       "      <td>6.629082e+08</td>\n",
       "      <td>Lennox International Inc., Q1 2020 Earnings Ca...</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAG7181</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285564</th>\n",
       "      <td>71862347</td>\n",
       "      <td>1836402</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>92894</td>\n",
       "      <td>I think that's just the lapping of the price i...</td>\n",
       "      <td>401541.0</td>\n",
       "      <td>6.396309e+08</td>\n",
       "      <td>Lennox International Inc., Q3 2019 Earnings Ca...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAG7181</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743620</th>\n",
       "      <td>48919024</td>\n",
       "      <td>1190065</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>142348</td>\n",
       "      <td>Well, there is seasonal element at play where ...</td>\n",
       "      <td>281083.0</td>\n",
       "      <td>4.239624e+08</td>\n",
       "      <td>Insteel Industries, Inc., Q2 2017 Earnings Cal...</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>3</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transcriptcomponentid  transcriptid  componentorder  \\\n",
       "468814                31993663        725629              49   \n",
       "1011148               60215643       1522835               8   \n",
       "17456                  6334028         89865              85   \n",
       "1132043               64895264       1646420              18   \n",
       "1536742               92190391       2424326              16   \n",
       "...                        ...           ...             ...   \n",
       "1352231               74570920       1900832               8   \n",
       "654168                44544860       1062834              53   \n",
       "1393007               76905869       1957524              20   \n",
       "1285564               71862347       1836402              48   \n",
       "743620                48919024       1190065              23   \n",
       "\n",
       "         transcriptcomponenttypeid  transcriptpersonid  \\\n",
       "468814                           4              104551   \n",
       "1011148                          4              324960   \n",
       "17456                            4               93028   \n",
       "1132043                          4              286913   \n",
       "1536742                          4              388038   \n",
       "...                            ...                 ...   \n",
       "1352231                          4               92894   \n",
       "654168                           4              120289   \n",
       "1393007                          4               92894   \n",
       "1285564                          4               92894   \n",
       "743620                           4              142348   \n",
       "\n",
       "                                             componenttext  companyid  \\\n",
       "468814   No, that's -- we're telling you to model that ...  1462309.0   \n",
       "1011148  Okay, Randy. So looking at SiP, we disclosed t...   124219.0   \n",
       "17456    I should say, Brendan, to your prior question ...   334962.0   \n",
       "1132043  Yes. Suji, we're expecting both divisions to b...    27307.0   \n",
       "1536742  Sure. Thanks, Joe, and thanks for the compleme...   310310.0   \n",
       "...                                                    ...        ...   \n",
       "1352231  The exact words that Joe used when he was talk...   401541.0   \n",
       "654168   Yes, I think if you look at really what we've ...   294338.0   \n",
       "1393007  Sure answer is yes to that final piece, which ...   401541.0   \n",
       "1285564  I think that's just the lapping of the price i...   401541.0   \n",
       "743620   Well, there is seasonal element at play where ...   281083.0   \n",
       "\n",
       "             keydevid                                           headline  \\\n",
       "468814   2.744932e+08  Skyworks Solutions Inc., Q4 2014 Earnings Call...   \n",
       "1011148  5.749385e+08  Amkor Technology, Inc., Q2 2018 Earnings Call,...   \n",
       "17456    8.493120e+07     ATMI Inc., Q3 2010 Earnings Call, Oct 20, 2010   \n",
       "1132043  5.984101e+08  Cypress Semiconductor Corporation, Q4 2018 Ear...   \n",
       "1536742  1.685657e+09  Unisys Corporation, Q3 2021 Earnings Call, Nov...   \n",
       "...               ...                                                ...   \n",
       "1352231  6.519870e+08  Lennox International Inc., Q4 2019 Earnings Ca...   \n",
       "654168   4.038350e+08  Owens Corning, Q3 2016 Earnings Call, Oct 26, ...   \n",
       "1393007  6.629082e+08  Lennox International Inc., Q1 2020 Earnings Ca...   \n",
       "1285564  6.396309e+08  Lennox International Inc., Q3 2019 Earnings Ca...   \n",
       "743620   4.239624e+08  Insteel Industries, Inc., Q2 2017 Earnings Cal...   \n",
       "\n",
       "        mostimportantdateutc  ...  sectordescription  subsectorcode  \\\n",
       "468814            2014-11-06  ...         Corporates           CORP   \n",
       "1011148           2018-07-30  ...         Corporates           CORP   \n",
       "17456             2010-10-20  ...         Corporates           CORP   \n",
       "1132043           2019-01-31  ...         Corporates           CORP   \n",
       "1536742           2021-11-03  ...         Corporates           CORP   \n",
       "...                      ...  ...                ...            ...   \n",
       "1352231           2020-02-04  ...         Corporates           CORP   \n",
       "654168            2016-10-26  ...         Corporates           CORP   \n",
       "1393007           2020-04-20  ...         Corporates           CORP   \n",
       "1285564           2019-10-21  ...         Corporates           CORP   \n",
       "743620            2017-04-20  ...         Corporates           CORP   \n",
       "\n",
       "        subsectordescription industrycode     industrydescription region  \\\n",
       "468814           Industrials            9  Information Technology    USA   \n",
       "1011148          Industrials            9  Information Technology    USA   \n",
       "17456            Industrials            9  Information Technology    USA   \n",
       "1132043          Industrials            9  Information Technology    USA   \n",
       "1536742          Industrials            9  Information Technology    USA   \n",
       "...                      ...          ...                     ...    ...   \n",
       "1352231          Industrials            3      Building Materials    USA   \n",
       "654168           Industrials            3      Building Materials    USA   \n",
       "1393007          Industrials            3      Building Materials    USA   \n",
       "1285564          Industrials            3      Building Materials    USA   \n",
       "743620           Industrials            3      Building Materials    USA   \n",
       "\n",
       "         countrycode munistate  analyst  naic  \n",
       "468814           USA        CA      CF0  None  \n",
       "1011148          USA        AZ      WER  None  \n",
       "17456            USA        CT     None  None  \n",
       "1132043          USA        CA  SES0001  None  \n",
       "1536742          USA        PA  SHP0006  None  \n",
       "...              ...       ...      ...   ...  \n",
       "1352231          USA        TX  PAG7181  None  \n",
       "654168           USA        OH  NIN4616  None  \n",
       "1393007          USA        TX  PAG7181  None  \n",
       "1285564          USA        TX  PAG7181  None  \n",
       "743620           USA        AL     None  None  \n",
       "\n",
       "[100 rows x 63 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a new dataframe from the list of dicts just created\n",
    "dummy_frame = pd.DataFrame.from_dict(dummy_data)\n",
    "dummy_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export this dummy frame to CSV for ease of manual annotation; we will then import the finished product, which will be used to test the BERT model framework\n",
    "dummy_frame.to_csv('datasets/dummy_frame_no_annot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the annotated dummy dataset and clean it for application to BERT tests\n",
    "dummy_frame_annot = pd.read_csv('datasets/dummy_frame_with_annot_trimmed_04.13.2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>companyid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33195823</td>\n",
       "      <td>757421</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>260824</td>\n",
       "      <td>-1</td>\n",
       "      <td>411950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19074161</td>\n",
       "      <td>404331</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>223947</td>\n",
       "      <td>-3</td>\n",
       "      <td>250859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67193600</td>\n",
       "      <td>1711480</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>257944</td>\n",
       "      <td>2</td>\n",
       "      <td>30439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6333958</td>\n",
       "      <td>89865</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>93035</td>\n",
       "      <td>-1</td>\n",
       "      <td>334962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19510305</td>\n",
       "      <td>413268</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>120923</td>\n",
       "      <td>-3</td>\n",
       "      <td>252150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>33912806</td>\n",
       "      <td>775609</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>274531</td>\n",
       "      <td>1</td>\n",
       "      <td>40084670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>51417429</td>\n",
       "      <td>1270021</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>137417</td>\n",
       "      <td>-1</td>\n",
       "      <td>34817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7668185</td>\n",
       "      <td>114989</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>148773</td>\n",
       "      <td>-3</td>\n",
       "      <td>379868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>48884376</td>\n",
       "      <td>1188990</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>116410</td>\n",
       "      <td>2</td>\n",
       "      <td>31153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>55047721</td>\n",
       "      <td>1377442</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>314544</td>\n",
       "      <td>3</td>\n",
       "      <td>338134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transcriptcomponentid  transcriptid  componentorder  \\\n",
       "0                33195823        757421              66   \n",
       "1                19074161        404331              28   \n",
       "2                67193600       1711480              81   \n",
       "3                 6333958         89865              15   \n",
       "4                19510305        413268               9   \n",
       "..                    ...           ...             ...   \n",
       "95               33912806        775609              50   \n",
       "96               51417429       1270021              31   \n",
       "97                7668185        114989              20   \n",
       "98               48884376       1188990              11   \n",
       "99               55047721       1377442              49   \n",
       "\n",
       "    transcriptcomponenttypeid  transcriptpersonid  Unnamed: 5  companyid  \n",
       "0                           4              260824          -1     411950  \n",
       "1                           4              223947          -3     250859  \n",
       "2                           4              257944           2      30439  \n",
       "3                           4               93035          -1     334962  \n",
       "4                           4              120923          -3     252150  \n",
       "..                        ...                 ...         ...        ...  \n",
       "95                          4              274531           1   40084670  \n",
       "96                          4              137417          -1      34817  \n",
       "97                          4              148773          -3     379868  \n",
       "98                          4              116410           2      31153  \n",
       "99                          4              314544           3     338134  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_frame_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the annotation id column (column 5)\n",
    "dummy_frame_annot.rename(columns = {\"Unnamed: 5\": \"Annot ID\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>Annot ID</th>\n",
       "      <th>companyid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33195823</td>\n",
       "      <td>757421</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>260824</td>\n",
       "      <td>-1</td>\n",
       "      <td>411950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19074161</td>\n",
       "      <td>404331</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>223947</td>\n",
       "      <td>-3</td>\n",
       "      <td>250859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67193600</td>\n",
       "      <td>1711480</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>257944</td>\n",
       "      <td>2</td>\n",
       "      <td>30439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6333958</td>\n",
       "      <td>89865</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>93035</td>\n",
       "      <td>-1</td>\n",
       "      <td>334962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19510305</td>\n",
       "      <td>413268</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>120923</td>\n",
       "      <td>-3</td>\n",
       "      <td>252150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transcriptcomponentid  transcriptid  componentorder  \\\n",
       "0               33195823        757421              66   \n",
       "1               19074161        404331              28   \n",
       "2               67193600       1711480              81   \n",
       "3                6333958         89865              15   \n",
       "4               19510305        413268               9   \n",
       "\n",
       "   transcriptcomponenttypeid  transcriptpersonid  Annot ID  companyid  \n",
       "0                          4              260824        -1     411950  \n",
       "1                          4              223947        -3     250859  \n",
       "2                          4              257944         2      30439  \n",
       "3                          4               93035        -1     334962  \n",
       "4                          4              120923        -3     252150  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the head of the dataset\n",
    "dummy_frame_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new dataframe that merges the annotation DF with the corresponding 'componenttext'; from this we will generate our X and y variables for the mode\n",
    "new_dummy_df = pd.merge(dummy_frame_annot, data_no_dup,  how='inner', \n",
    "                        left_on=['transcriptcomponentid','transcriptid'], \n",
    "                        right_on = ['transcriptcomponentid','transcriptid'])\n",
    "new_dummy_df = new_dummy_df[['transcriptcomponentid','transcriptid', 'Annot ID', 'companyid_x', 'componenttext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>Annot ID</th>\n",
       "      <th>companyid_x</th>\n",
       "      <th>componenttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33195823</td>\n",
       "      <td>757421</td>\n",
       "      <td>-1</td>\n",
       "      <td>411950</td>\n",
       "      <td>Well, obviously, it would flatten it out a bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19074161</td>\n",
       "      <td>404331</td>\n",
       "      <td>-3</td>\n",
       "      <td>250859</td>\n",
       "      <td>Yes. Absolutely this business has fallen well ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67193600</td>\n",
       "      <td>1711480</td>\n",
       "      <td>2</td>\n",
       "      <td>30439</td>\n",
       "      <td>Yes, so, I believe you're referring to the com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6333958</td>\n",
       "      <td>89865</td>\n",
       "      <td>-1</td>\n",
       "      <td>334962</td>\n",
       "      <td>If I look back over the last few years, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19510305</td>\n",
       "      <td>413268</td>\n",
       "      <td>-3</td>\n",
       "      <td>252150</td>\n",
       "      <td>All right. Thanks. Well, we're actually seeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>33912806</td>\n",
       "      <td>775609</td>\n",
       "      <td>1</td>\n",
       "      <td>40084670</td>\n",
       "      <td>Thank you, everyone, for joining us today on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>51417429</td>\n",
       "      <td>1270021</td>\n",
       "      <td>-1</td>\n",
       "      <td>34817</td>\n",
       "      <td>I'll give you my thoughts. I think the little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7668185</td>\n",
       "      <td>114989</td>\n",
       "      <td>-3</td>\n",
       "      <td>379868</td>\n",
       "      <td>Lee, looking at -- I mean, it's so difficult t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>48884376</td>\n",
       "      <td>1188990</td>\n",
       "      <td>2</td>\n",
       "      <td>31153</td>\n",
       "      <td>Yes, I guess, our sense on that, Garik, was we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>55047721</td>\n",
       "      <td>1377442</td>\n",
       "      <td>3</td>\n",
       "      <td>338134</td>\n",
       "      <td>We don't think we need to add any. There is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transcriptcomponentid  transcriptid  Annot ID  companyid_x  \\\n",
       "0                33195823        757421        -1       411950   \n",
       "1                19074161        404331        -3       250859   \n",
       "2                67193600       1711480         2        30439   \n",
       "3                 6333958         89865        -1       334962   \n",
       "4                19510305        413268        -3       252150   \n",
       "..                    ...           ...       ...          ...   \n",
       "95               33912806        775609         1     40084670   \n",
       "96               51417429       1270021        -1        34817   \n",
       "97                7668185        114989        -3       379868   \n",
       "98               48884376       1188990         2        31153   \n",
       "99               55047721       1377442         3       338134   \n",
       "\n",
       "                                        componenttext  \n",
       "0   Well, obviously, it would flatten it out a bit...  \n",
       "1   Yes. Absolutely this business has fallen well ...  \n",
       "2   Yes, so, I believe you're referring to the com...  \n",
       "3   If I look back over the last few years, I woul...  \n",
       "4   All right. Thanks. Well, we're actually seeing...  \n",
       "..                                                ...  \n",
       "95  Thank you, everyone, for joining us today on t...  \n",
       "96  I'll give you my thoughts. I think the little ...  \n",
       "97  Lee, looking at -- I mean, it's so difficult t...  \n",
       "98  Yes, I guess, our sense on that, Garik, was we...  \n",
       "99  We don't think we need to add any. There is a ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This BERT Model does not work with classifier values less than zero; we will use a dict to map our Annotation IDs to positive values for the purposes\n",
    "# of fitting the model\n",
    "mapping_dict = {-3:0, -2:1, -1:2, 0:3, 1:4, 2:5, 3:6}\n",
    "new_dummy_df['Annot ID'].replace(mapping_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>Annot ID</th>\n",
       "      <th>companyid_x</th>\n",
       "      <th>componenttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33195823</td>\n",
       "      <td>757421</td>\n",
       "      <td>2</td>\n",
       "      <td>411950</td>\n",
       "      <td>Well, obviously, it would flatten it out a bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19074161</td>\n",
       "      <td>404331</td>\n",
       "      <td>0</td>\n",
       "      <td>250859</td>\n",
       "      <td>Yes. Absolutely this business has fallen well ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67193600</td>\n",
       "      <td>1711480</td>\n",
       "      <td>5</td>\n",
       "      <td>30439</td>\n",
       "      <td>Yes, so, I believe you're referring to the com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6333958</td>\n",
       "      <td>89865</td>\n",
       "      <td>2</td>\n",
       "      <td>334962</td>\n",
       "      <td>If I look back over the last few years, I woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19510305</td>\n",
       "      <td>413268</td>\n",
       "      <td>0</td>\n",
       "      <td>252150</td>\n",
       "      <td>All right. Thanks. Well, we're actually seeing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>33912806</td>\n",
       "      <td>775609</td>\n",
       "      <td>4</td>\n",
       "      <td>40084670</td>\n",
       "      <td>Thank you, everyone, for joining us today on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>51417429</td>\n",
       "      <td>1270021</td>\n",
       "      <td>2</td>\n",
       "      <td>34817</td>\n",
       "      <td>I'll give you my thoughts. I think the little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7668185</td>\n",
       "      <td>114989</td>\n",
       "      <td>0</td>\n",
       "      <td>379868</td>\n",
       "      <td>Lee, looking at -- I mean, it's so difficult t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>48884376</td>\n",
       "      <td>1188990</td>\n",
       "      <td>5</td>\n",
       "      <td>31153</td>\n",
       "      <td>Yes, I guess, our sense on that, Garik, was we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>55047721</td>\n",
       "      <td>1377442</td>\n",
       "      <td>6</td>\n",
       "      <td>338134</td>\n",
       "      <td>We don't think we need to add any. There is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transcriptcomponentid  transcriptid  Annot ID  companyid_x  \\\n",
       "0                33195823        757421         2       411950   \n",
       "1                19074161        404331         0       250859   \n",
       "2                67193600       1711480         5        30439   \n",
       "3                 6333958         89865         2       334962   \n",
       "4                19510305        413268         0       252150   \n",
       "..                    ...           ...       ...          ...   \n",
       "95               33912806        775609         4     40084670   \n",
       "96               51417429       1270021         2        34817   \n",
       "97                7668185        114989         0       379868   \n",
       "98               48884376       1188990         5        31153   \n",
       "99               55047721       1377442         6       338134   \n",
       "\n",
       "                                        componenttext  \n",
       "0   Well, obviously, it would flatten it out a bit...  \n",
       "1   Yes. Absolutely this business has fallen well ...  \n",
       "2   Yes, so, I believe you're referring to the com...  \n",
       "3   If I look back over the last few years, I woul...  \n",
       "4   All right. Thanks. Well, we're actually seeing...  \n",
       "..                                                ...  \n",
       "95  Thank you, everyone, for joining us today on t...  \n",
       "96  I'll give you my thoughts. I think the little ...  \n",
       "97  Lee, looking at -- I mean, it's so difficult t...  \n",
       "98  Yes, I guess, our sense on that, Garik, was we...  \n",
       "99  We don't think we need to add any. There is a ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 5, 4, 1, 3, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should find unique identifiers ranging from zero theu 6\n",
    "new_dummy_df['Annot ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train, validation and test datasets for the model to be fit below\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = new_dummy_df.componenttext.values\n",
    "y = new_dummy_df['Annot ID'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=3) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching gears now to work on the BERT model that will be fine-tuned for our work\n",
    "# Source code located at: https://skimai.com/fine-tuning-bert-for-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this iteration of the model, we will be using PyTorch; we will import the appropriate packages here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "# For package compatibility reasons, let's check the version of Python being used\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "# Need to direct Torch to use the GPU\n",
    "# Using the accelerate library by Hugging Face (https://huggingface.co/blog/accelerate-library)\n",
    "\n",
    "#accelerator = Accelerator()\n",
    "#device = accelerator.device\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is showing errors when fitting the BERT model, it is recommend we switch to CPU to engage in troubleshooting steps\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will preprocess text for preparation for the BERT model;\n",
    "# NOTE: BERT was trained on full sentences, so less pre-processing needs to take place\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Well, certainly. I think as we go through the build-up of our loan loss\n",
      "reserve, it's something that we have to go through and document each and every\n",
      "quarter. As non-performers increase as you seek just normal migration in credit,\n",
      "I think there's the normal expectation that as charge-offs go up and this time\n",
      "the cycle that provision will also end up going up just like it did in the\n",
      "third quarter, we had ended up providing more than what we charged off. So,\n",
      "that particular pattern could exist in future periods as we continue to go\n",
      "through the cycle.\n",
      "Processed:  Well, certainly. I think as we go through the build-up of our loan loss reserve, it's something that we have to go through and document each and every quarter. As non-performers increase as you seek just normal migration in credit, I think there's the normal expectation that as charge-offs go up and this time the cycle that provision will also end up going up just like it did in the third quarter, we had ended up providing more than what we charged off. So, that particular pattern could exist in future periods as we continue to go through the cycle.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the preprocessing using an example\n",
    "# Print sentence 0\n",
    "\n",
    "print('Original: ', data_no_dup['componenttext'][1000])\n",
    "print('Processed: ', text_preprocessing(data_no_dup['componenttext'][1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "# Set the maximum token length to be used in this iteration of the model; tokens after the max length are truncated\n",
    "# NOTE: Need to change truncation so it occurs on the front, and not back, end of the model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, model_max_length=128, truncation=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (129 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  475\n"
     ]
    }
   ],
   "source": [
    "# Before tokenizing, we need to specify the maximum length of our responses\n",
    "\n",
    "# Concatenate train, val and test data\n",
    "all_data = np.concatenate([X_train, X_val, X_test])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_text = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_data]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_text])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20912\n"
     ]
    }
   ],
   "source": [
    "# How to check the length of the longest entry in the dataset\n",
    "# NOTE: Not needed for this exact exercise, but will be needed for final work\n",
    "len_list = [len(entry) for entry in data_no_dup['componenttext']]\n",
    "print(len(data_no_dup['componenttext'][len_list.index((max(len_list)))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  \n",
      " Well, obviously, it would flatten it out a bit. You're still going to have big quarters in Q2 and Q3, but what you'll have maybe is a little flatter performance in 4 and 1. \n",
      "\n",
      "Token IDs:  \n",
      " [101, 2092, 1010, 5525, 1010, 2009, 2052, 4257, 6528, 2009, 2041, 1037, 2978, 1012, 2017, 1005, 2128, 2145, 2183, 2000, 2031, 2502, 7728, 1999, 1053, 2475, 1998, 1053, 2509, 1010, 2021, 2054, 2017, 1005, 2222, 2031, 2672, 2003, 1037, 2210, 4257, 3334, 2836, 1999, 1018, 1998, 1015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "Convert IDs tok Tokens:  \n",
      " ['[CLS]', 'well', ',', 'obviously', ',', 'it', 'would', 'flat', '##ten', 'it', 'out', 'a', 'bit', '.', 'you', \"'\", 're', 'still', 'going', 'to', 'have', 'big', 'quarters', 'in', 'q', '##2', 'and', 'q', '##3', ',', 'but', 'what', 'you', \"'\", 'll', 'have', 'maybe', 'is', 'a', 'little', 'flat', '##ter', 'performance', 'in', '4', 'and', '1', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
      "\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', '\\n', X[0], '\\n')\n",
    "print('Token IDs: ', '\\n', token_ids, '\\n')\n",
    "print('Convert IDs tok Tokens: ', '\\n', tokenizer.convert_ids_to_tokens(token_ids), '\\n' )\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed.\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 5, 3, 4, 1, 2, 3, 4, 3, 1, 1, 4, 4, 6, 4, 4, 6, 2, 3, 6, 2, 3, 4,\n",
       "        4, 4, 6, 5, 3, 4, 4, 3, 4, 3, 5, 2, 5, 3, 2, 5, 3, 2, 4, 4, 6, 3, 3, 0,\n",
       "        2, 4, 3, 3, 5, 6, 4, 4, 2, 0, 0, 6])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first slice of the training labels tensor to better understand the data preparation steps\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Check to ensure that each of the classification categories are represented in our train, validation and test datasets\n",
    "# by viewing the unique values in each dataset, which should align\n",
    "print(np.unique(y_train))\n",
    "print(np.unique(y_val))\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformers library has the BertForSequenceClassification class which is designed for classification tasks. However, we will create a new class \n",
    "# so we can specify our own choice of classifiers.\n",
    "\n",
    "# Below we will create a BertClassifier class with a BERT model to extract the last hidden layer of the [CLS] token and a single-hidden-layer feed-forward \n",
    "# neural network as our classifier.\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 7\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #self.bert = nn.DataParallel(BertModel.from_pretrained('bert-base-uncased'))\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "    \n",
    "    # NEW LINE ADDED BY JAY\n",
    "    #bert_classifier = nn.DataParallel(bert_classifier)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    #torch.manual_seed(seed_value)\n",
    "    #torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to clear GPU cache before running model\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "#del variables\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to display the GPU memory utilization so we can help diagnose potential memory constraint issues\n",
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 574 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of recognized GPUs by Torch on this device\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |    3    |   1.933992   |     -      |     -     |   1.03   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   1.933992   |  1.978820  |   6.25    |   1.10   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |    3    |   1.778666   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   1.778666   |  2.006191  |   18.75   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |    3    |   1.593350   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   1.593350   |  1.998351  |   6.25    |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |    3    |   1.415658   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   1.415658   |  1.962991  |   6.25    |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |    3    |   1.245523   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   1.245523   |  1.902284  |   18.75   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   6    |    3    |   1.043603   |     -      |     -     |   0.67   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   1.043603   |  1.909538  |   18.75   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   7    |    3    |   0.908810   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.908810   |  1.895342  |   21.88   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   8    |    3    |   0.771458   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.771458   |  1.939147  |   18.75   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   9    |    3    |   0.677454   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.677454   |  1.907490  |   37.50   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  10    |    3    |   0.576111   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.576111   |  1.891018  |   28.12   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  11    |    3    |   0.472834   |     -      |     -     |   0.68   \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.472834   |  1.938292  |   34.38   |   0.74   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  12    |    3    |   0.417089   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.417089   |  1.933283  |   37.50   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  13    |    3    |   0.362170   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.362170   |  1.918050  |   37.50   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  14    |    3    |   0.317019   |     -      |     -     |   0.67   \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.317019   |  1.992698  |   37.50   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  15    |    3    |   0.293944   |     -      |     -     |   0.67   \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.293944   |  1.972522  |   37.50   |   0.73   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  16    |    3    |   0.264291   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.264291   |  2.005431  |   40.62   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  17    |    3    |   0.241936   |     -      |     -     |   0.66   \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.241936   |  2.051086  |   28.12   |   0.72   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  18    |    3    |   0.227439   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.227439   |  2.050062  |   28.12   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  19    |    3    |   0.221695   |     -      |     -     |   0.67   \n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.221695   |  2.052946  |   28.12   |   0.73   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  20    |    3    |   0.213397   |     -      |     -     |   0.65   \n",
      "----------------------------------------------------------------------\n",
      "  20    |    -    |   0.213397   |  2.048114  |   28.12   |   0.71   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# By adding this first line of code to our executables, we can derive more detailed error messages if issues arise with the GPU\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Initialize the BERTClassifier model and run two epochs on the training data\n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=20)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=20, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The above demonstration of fitting the BERT model was solely as an exercise in demonstrating the feasibility of the task;\n",
    "# Now, we will turn to generating an annotated dataset containing 1,000 datapoints. This dataset will form the first stage of our\n",
    "# analytical task in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a subset of our 'data_no_dup' dataset in which all entries in the 'componettext' field contain a minimum of 10 tokens, in order to eliminate\n",
    "# some of the least useful entries that fail to reveal sentiments and are merely one, or several word answers to posed questions\n",
    "data_no_dup_min_10 = []\n",
    "\n",
    "for i in range(len(data_no_dup)):\n",
    "    if len(data_no_dup['componenttext'].loc[i].split()) >= 10:\n",
    "        data_no_dup_min_10.append(data_no_dup.loc[i]);\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>companyid</th>\n",
       "      <th>keydevid</th>\n",
       "      <th>headline</th>\n",
       "      <th>mostimportantdateutc</th>\n",
       "      <th>...</th>\n",
       "      <th>sectordescription</th>\n",
       "      <th>subsectorcode</th>\n",
       "      <th>subsectordescription</th>\n",
       "      <th>industrycode</th>\n",
       "      <th>industrydescription</th>\n",
       "      <th>region</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>munistate</th>\n",
       "      <th>analyst</th>\n",
       "      <th>naic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70732045</td>\n",
       "      <td>1806760</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Yes Toni, for your first question you are quit...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70732048</td>\n",
       "      <td>1806760</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Yeah let me first startup let say we are prett...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70732051</td>\n",
       "      <td>1806760</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Well first of all I will let start very good q...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70732054</td>\n",
       "      <td>1806760</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Well let’s say let’s look at this way as we fi...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70732057</td>\n",
       "      <td>1806760</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8971</td>\n",
       "      <td>Yeah, that’s a good question. First of all as ...</td>\n",
       "      <td>112350.0</td>\n",
       "      <td>2.518499e+06</td>\n",
       "      <td>International Business Machines Corp., Q4 2005...</td>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>9</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NY</td>\n",
       "      <td>DDT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539718</th>\n",
       "      <td>93249236</td>\n",
       "      <td>2460158</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "      <td>115049</td>\n",
       "      <td>No. I was just going to add that we do want to...</td>\n",
       "      <td>279534.0</td>\n",
       "      <td>1.759968e+09</td>\n",
       "      <td>Hovnanian Enterprises, Inc., Q4 2021 Earnings ...</td>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>...</td>\n",
       "      <td>Structured Finance</td>\n",
       "      <td>REC</td>\n",
       "      <td>Real Estate Companies</td>\n",
       "      <td>PROPRE</td>\n",
       "      <td>Property &amp; Real Estate</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NJ</td>\n",
       "      <td>WIM0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539719</th>\n",
       "      <td>93249238</td>\n",
       "      <td>2460158</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>115049</td>\n",
       "      <td>Thank you very much. As we said, we're pleased...</td>\n",
       "      <td>279534.0</td>\n",
       "      <td>1.759968e+09</td>\n",
       "      <td>Hovnanian Enterprises, Inc., Q4 2021 Earnings ...</td>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>...</td>\n",
       "      <td>Structured Finance</td>\n",
       "      <td>REC</td>\n",
       "      <td>Real Estate Companies</td>\n",
       "      <td>PROPRE</td>\n",
       "      <td>Property &amp; Real Estate</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>NJ</td>\n",
       "      <td>WIM0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539720</th>\n",
       "      <td>93263873</td>\n",
       "      <td>2460657</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>John, are you still there? Did you drop? We lo...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539722</th>\n",
       "      <td>93263878</td>\n",
       "      <td>2460657</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>So as you know, it's a very good question beca...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539724</th>\n",
       "      <td>93263882</td>\n",
       "      <td>2460657</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>452213</td>\n",
       "      <td>Thank you, operator. We are very optimistic ab...</td>\n",
       "      <td>561218649.0</td>\n",
       "      <td>1.759951e+09</td>\n",
       "      <td>KLX Energy Services Holdings, Inc., Q3 2022 Ea...</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporates</td>\n",
       "      <td>CORP</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>20</td>\n",
       "      <td>Energy</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>TX</td>\n",
       "      <td>PAO0002</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1355629 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         transcriptcomponentid  transcriptid  componentorder  \\\n",
       "0                     70732045       1806760               5   \n",
       "1                     70732048       1806760               8   \n",
       "2                     70732051       1806760              11   \n",
       "3                     70732054       1806760              14   \n",
       "4                     70732057       1806760              17   \n",
       "...                        ...           ...             ...   \n",
       "1539718               93249236       2460158              96   \n",
       "1539719               93249238       2460158              98   \n",
       "1539720               93263873       2460657               6   \n",
       "1539722               93263878       2460657              11   \n",
       "1539724               93263882       2460657              15   \n",
       "\n",
       "         transcriptcomponenttypeid  transcriptpersonid  \\\n",
       "0                                4                8971   \n",
       "1                                4                8971   \n",
       "2                                4                8971   \n",
       "3                                4                8971   \n",
       "4                                4                8971   \n",
       "...                            ...                 ...   \n",
       "1539718                          4              115049   \n",
       "1539719                          4              115049   \n",
       "1539720                          4              452213   \n",
       "1539722                          4              452213   \n",
       "1539724                          4              452213   \n",
       "\n",
       "                                             componenttext    companyid  \\\n",
       "0        Yes Toni, for your first question you are quit...     112350.0   \n",
       "1        Yeah let me first startup let say we are prett...     112350.0   \n",
       "2        Well first of all I will let start very good q...     112350.0   \n",
       "3        Well let’s say let’s look at this way as we fi...     112350.0   \n",
       "4        Yeah, that’s a good question. First of all as ...     112350.0   \n",
       "...                                                    ...          ...   \n",
       "1539718  No. I was just going to add that we do want to...     279534.0   \n",
       "1539719  Thank you very much. As we said, we're pleased...     279534.0   \n",
       "1539720  John, are you still there? Did you drop? We lo...  561218649.0   \n",
       "1539722  So as you know, it's a very good question beca...  561218649.0   \n",
       "1539724  Thank you, operator. We are very optimistic ab...  561218649.0   \n",
       "\n",
       "             keydevid                                           headline  \\\n",
       "0        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "1        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "2        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "3        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "4        2.518499e+06  International Business Machines Corp., Q4 2005...   \n",
       "...               ...                                                ...   \n",
       "1539718  1.759968e+09  Hovnanian Enterprises, Inc., Q4 2021 Earnings ...   \n",
       "1539719  1.759968e+09  Hovnanian Enterprises, Inc., Q4 2021 Earnings ...   \n",
       "1539720  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "1539722  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "1539724  1.759951e+09  KLX Energy Services Holdings, Inc., Q3 2022 Ea...   \n",
       "\n",
       "        mostimportantdateutc  ...   sectordescription  subsectorcode  \\\n",
       "0                 2006-01-17  ...          Corporates           CORP   \n",
       "1                 2006-01-17  ...          Corporates           CORP   \n",
       "2                 2006-01-17  ...          Corporates           CORP   \n",
       "3                 2006-01-17  ...          Corporates           CORP   \n",
       "4                 2006-01-17  ...          Corporates           CORP   \n",
       "...                      ...  ...                 ...            ...   \n",
       "1539718           2021-12-09  ...  Structured Finance            REC   \n",
       "1539719           2021-12-09  ...  Structured Finance            REC   \n",
       "1539720           2021-12-10  ...          Corporates           CORP   \n",
       "1539722           2021-12-10  ...          Corporates           CORP   \n",
       "1539724           2021-12-10  ...          Corporates           CORP   \n",
       "\n",
       "          subsectordescription industrycode     industrydescription region  \\\n",
       "0                  Industrials            9  Information Technology    USA   \n",
       "1                  Industrials            9  Information Technology    USA   \n",
       "2                  Industrials            9  Information Technology    USA   \n",
       "3                  Industrials            9  Information Technology    USA   \n",
       "4                  Industrials            9  Information Technology    USA   \n",
       "...                        ...          ...                     ...    ...   \n",
       "1539718  Real Estate Companies       PROPRE  Property & Real Estate    USA   \n",
       "1539719  Real Estate Companies       PROPRE  Property & Real Estate    USA   \n",
       "1539720            Industrials           20                  Energy    USA   \n",
       "1539722            Industrials           20                  Energy    USA   \n",
       "1539724            Industrials           20                  Energy    USA   \n",
       "\n",
       "         countrycode munistate  analyst  naic  \n",
       "0                USA        NY      DDT  None  \n",
       "1                USA        NY      DDT  None  \n",
       "2                USA        NY      DDT  None  \n",
       "3                USA        NY      DDT  None  \n",
       "4                USA        NY      DDT  None  \n",
       "...              ...       ...      ...   ...  \n",
       "1539718          USA        NJ  WIM0002  None  \n",
       "1539719          USA        NJ  WIM0002  None  \n",
       "1539720          USA        TX  PAO0002  None  \n",
       "1539722          USA        TX  PAO0002  None  \n",
       "1539724          USA        TX  PAO0002  None  \n",
       "\n",
       "[1355629 rows x 63 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a dataframe from this new subset dataset\n",
    "data_no_dup_min_10 = pd.DataFrame.from_dict(data_no_dup_min_10)\n",
    "data_no_dup_min_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1146361"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_dup_min_10['industrydescription'].value_counts()[:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the loop generated above to create a \"generate_data\" function that can be used to produce the required random samples from the \n",
    "# industries we wish to scrutinize\n",
    "\n",
    "def generate_data(seed, dataset, series_name, num_obs_per_series, replace=False):\n",
    "\n",
    "    # First, instantiate an empty list that will be populated with the data, as it is randomly selected from each industry group\n",
    "    data = []\n",
    "\n",
    "    # Generate a loop that goes through the top 20 industries, as identified view value counts, and then randomly selects 5 entries from that \n",
    "    # industry for addition to the dummy data set\n",
    "    for i in range(0, 20):\n",
    "        # Set a seed for reproducibility of results\n",
    "        np.random.seed(seed)\n",
    "        # This code produces a random list of the index location of 50 elements for each of the top 20 industry subsets\n",
    "        current_elements = np.random.choice(\n",
    "            dataset[dataset[series_name] == dataset[series_name].value_counts().index[i]].index.tolist(),\n",
    "            size = num_obs_per_series,\n",
    "            replace = replace)\n",
    "        \n",
    "        # Using the list of index locations above, this loop appends each row associated with a given index item to a list, generating a list of dicts\n",
    "        for j in range(len(current_elements)):\n",
    "            # Set a seed for reproductibility of results\n",
    "            np.random.seed(seed)\n",
    "            current_obs = dataset[dataset[series_name] == dataset[series_name]].loc[current_elements[j]]\n",
    "            data.append(current_obs)\n",
    "    \n",
    "    # return a dataframe of the obtained data\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function defined above to generate a 1,000 point dataset upon which sentiment annotations can be made\n",
    "obs_subset_for_annot = generate_data(seed=1234, dataset=data_no_dup_min_10, series_name='industrydescription', num_obs_per_series=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the output dataset and remove all columns outside of transcript component id, transcript id, company id, company name and component text\n",
    "# Retaining these key identiers will permit for merging with the broader dataset, if needed, at a later point in time\n",
    "obs_subset_for_annot_trimmed = obs_subset_for_annot[['transcriptcomponentid', 'transcriptid', 'companyid', \n",
    "                                                                         'companyname', 'componenttext']]\n",
    "# Send the CSV of this new dataset to file\n",
    "obs_subset_for_annot_trimmed.to_csv('datasets/1000_datapoints_annotation_set.csv')\n",
    "# View the head and tail of this new dataset\n",
    "obs_subset_for_annot_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also generate a shuffled version of the above datatset, so the sectors represented in the dataset are not all shown together, which could lead\n",
    "# to distortions in rankings if sector-level language influences sentiment scoring by annotators\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle the dataframe\n",
    "obs_subset_for_annot_trimmed_shuffled = shuffle(obs_subset_for_annot_trimmed)\n",
    "# Send the shuffled dataframe to CSV\n",
    "obs_subset_for_annot_trimmed_shuffled.to_csv('datasets/1000_datapoints_annotation_set_shuffled.csv')\n",
    "# View a slice of the shuffled dataframe\n",
    "obs_subset_for_annot_trimmed_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an instance of the classifier model so we can view some of the descriptive information available regarding the model\n",
    "test_model = BertClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the configuration of the model (i.e. layers, outputs, etc.)\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the parameters weights of the model\n",
    "#for para in test_model.parameters():\n",
    "#    print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now load in both of the annotator's datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332580</td>\n",
       "      <td>21626174</td>\n",
       "      <td>463004</td>\n",
       "      <td>30054660</td>\n",
       "      <td>Ditech Holding Corporation</td>\n",
       "      <td>Some of them have. Some of them are the funded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439149</td>\n",
       "      <td>29670621</td>\n",
       "      <td>667025</td>\n",
       "      <td>381997</td>\n",
       "      <td>Headwaters Incorporated</td>\n",
       "      <td>So with that, we will go ahead and conclude th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387435</td>\n",
       "      <td>76257909</td>\n",
       "      <td>1943128</td>\n",
       "      <td>30822601</td>\n",
       "      <td>Northern Oil and Gas, Inc.</td>\n",
       "      <td>So on the bonds, obviously, what I said in my ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574255</td>\n",
       "      <td>40819900</td>\n",
       "      <td>961528</td>\n",
       "      <td>34952431</td>\n",
       "      <td>Kinder Morgan, Inc.</td>\n",
       "      <td>I think that they're being cautious about thei...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505727</td>\n",
       "      <td>35203566</td>\n",
       "      <td>809487</td>\n",
       "      <td>6469353</td>\n",
       "      <td>Scripps Networks Interactive, Inc.</td>\n",
       "      <td>Yes, this is Burton. Just to clarify, no, the ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1473535</td>\n",
       "      <td>82312408</td>\n",
       "      <td>2094667</td>\n",
       "      <td>334158</td>\n",
       "      <td>Ingersoll Rand Inc.</td>\n",
       "      <td>Sure. Yes. So let me kind of take them in piec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1098188</td>\n",
       "      <td>63457785</td>\n",
       "      <td>1610373</td>\n",
       "      <td>84223462</td>\n",
       "      <td>Phillips Edison &amp; Company, Inc.</td>\n",
       "      <td>Sure. Tom, as you know, our current annual div...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>620056</td>\n",
       "      <td>43058235</td>\n",
       "      <td>1022183</td>\n",
       "      <td>183811756</td>\n",
       "      <td>Press Ganey Holdings, Inc.</td>\n",
       "      <td>Sure, happy to do that. So the nursing perform...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>873979</td>\n",
       "      <td>53941617</td>\n",
       "      <td>1345650</td>\n",
       "      <td>270315</td>\n",
       "      <td>Esterline Technologies Corporation</td>\n",
       "      <td>Yes. I think that phasing is very, very import...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1152329</td>\n",
       "      <td>65639087</td>\n",
       "      <td>1664503</td>\n",
       "      <td>293515</td>\n",
       "      <td>FirstEnergy Corp.</td>\n",
       "      <td>I would say -- I'll give you an example, not s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  transcriptcomponentid  transcriptid  companyid  \\\n",
       "0        332580               21626174        463004   30054660   \n",
       "1        439149               29670621        667025     381997   \n",
       "2       1387435               76257909       1943128   30822601   \n",
       "3        574255               40819900        961528   34952431   \n",
       "4        505727               35203566        809487    6469353   \n",
       "..          ...                    ...           ...        ...   \n",
       "995     1473535               82312408       2094667     334158   \n",
       "996     1098188               63457785       1610373   84223462   \n",
       "997      620056               43058235       1022183  183811756   \n",
       "998      873979               53941617       1345650     270315   \n",
       "999     1152329               65639087       1664503     293515   \n",
       "\n",
       "                            companyname  \\\n",
       "0            Ditech Holding Corporation   \n",
       "1               Headwaters Incorporated   \n",
       "2            Northern Oil and Gas, Inc.   \n",
       "3                   Kinder Morgan, Inc.   \n",
       "4    Scripps Networks Interactive, Inc.   \n",
       "..                                  ...   \n",
       "995                 Ingersoll Rand Inc.   \n",
       "996     Phillips Edison & Company, Inc.   \n",
       "997          Press Ganey Holdings, Inc.   \n",
       "998  Esterline Technologies Corporation   \n",
       "999                   FirstEnergy Corp.   \n",
       "\n",
       "                                         componenttext  Rating  \n",
       "0    Some of them have. Some of them are the funded...       0  \n",
       "1    So with that, we will go ahead and conclude th...       0  \n",
       "2    So on the bonds, obviously, what I said in my ...       2  \n",
       "3    I think that they're being cautious about thei...      -1  \n",
       "4    Yes, this is Burton. Just to clarify, no, the ...       2  \n",
       "..                                                 ...     ...  \n",
       "995  Sure. Yes. So let me kind of take them in piec...       1  \n",
       "996  Sure. Tom, as you know, our current annual div...       0  \n",
       "997  Sure, happy to do that. So the nursing perform...       2  \n",
       "998  Yes. I think that phasing is very, very import...      -2  \n",
       "999  I would say -- I'll give you an example, not s...       1  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in first annotator's dataset\n",
    "jdv_annot = pd.read_csv('datasets/1000_datapoints_annotation_set_shuffled_JayAnnot_04.19.2022.csv')\n",
    "jdv_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                int64\n",
       "transcriptcomponentid     int64\n",
       "transcriptid              int64\n",
       "companyid                 int64\n",
       "companyname              object\n",
       "componenttext            object\n",
       "Rating                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the annotation ranking series only contains the datatypes and values that are expected\n",
    "jdv_annot.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2, -1,  3,  1, -2, -3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the annotation ranking series only contains the datatypes and values that are expected\n",
    "jdv_annot['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Rating', ylabel='count'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generat a histogram of the categoricals from Jay's annotations\n",
    "# NOTE: The categoricals skew in the positive direction; also, neutral, or near-neutral ratings are most frequent\n",
    "sns.countplot(jdv_annot['Rating'], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332580</td>\n",
       "      <td>21626174</td>\n",
       "      <td>463004</td>\n",
       "      <td>30054660</td>\n",
       "      <td>Ditech Holding Corporation</td>\n",
       "      <td>Some of them have. Some of them are the funded...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439149</td>\n",
       "      <td>29670621</td>\n",
       "      <td>667025</td>\n",
       "      <td>381997</td>\n",
       "      <td>Headwaters Incorporated</td>\n",
       "      <td>So with that, we will go ahead and conclude th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387435</td>\n",
       "      <td>76257909</td>\n",
       "      <td>1943128</td>\n",
       "      <td>30822601</td>\n",
       "      <td>Northern Oil and Gas, Inc.</td>\n",
       "      <td>So on the bonds, obviously, what I said in my ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574255</td>\n",
       "      <td>40819900</td>\n",
       "      <td>961528</td>\n",
       "      <td>34952431</td>\n",
       "      <td>Kinder Morgan, Inc.</td>\n",
       "      <td>I think that they're being cautious about thei...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505727</td>\n",
       "      <td>35203566</td>\n",
       "      <td>809487</td>\n",
       "      <td>6469353</td>\n",
       "      <td>Scripps Networks Interactive, Inc.</td>\n",
       "      <td>Yes, this is Burton. Just to clarify, no, the ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1473535</td>\n",
       "      <td>82312408</td>\n",
       "      <td>2094667</td>\n",
       "      <td>334158</td>\n",
       "      <td>Ingersoll Rand Inc.</td>\n",
       "      <td>Sure. Yes. So let me kind of take them in piec...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1098188</td>\n",
       "      <td>63457785</td>\n",
       "      <td>1610373</td>\n",
       "      <td>84223462</td>\n",
       "      <td>Phillips Edison &amp; Company, Inc.</td>\n",
       "      <td>Sure. Tom, as you know, our current annual div...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>620056</td>\n",
       "      <td>43058235</td>\n",
       "      <td>1022183</td>\n",
       "      <td>183811756</td>\n",
       "      <td>Press Ganey Holdings, Inc.</td>\n",
       "      <td>Sure, happy to do that. So the nursing perform...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>873979</td>\n",
       "      <td>53941617</td>\n",
       "      <td>1345650</td>\n",
       "      <td>270315</td>\n",
       "      <td>Esterline Technologies Corporation</td>\n",
       "      <td>Yes. I think that phasing is very, very import...</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1152329</td>\n",
       "      <td>65639087</td>\n",
       "      <td>1664503</td>\n",
       "      <td>293515</td>\n",
       "      <td>FirstEnergy Corp.</td>\n",
       "      <td>I would say -- I'll give you an example, not s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  transcriptcomponentid  transcriptid  companyid  \\\n",
       "0        332580               21626174        463004   30054660   \n",
       "1        439149               29670621        667025     381997   \n",
       "2       1387435               76257909       1943128   30822601   \n",
       "3        574255               40819900        961528   34952431   \n",
       "4        505727               35203566        809487    6469353   \n",
       "..          ...                    ...           ...        ...   \n",
       "995     1473535               82312408       2094667     334158   \n",
       "996     1098188               63457785       1610373   84223462   \n",
       "997      620056               43058235       1022183  183811756   \n",
       "998      873979               53941617       1345650     270315   \n",
       "999     1152329               65639087       1664503     293515   \n",
       "\n",
       "                            companyname  \\\n",
       "0            Ditech Holding Corporation   \n",
       "1               Headwaters Incorporated   \n",
       "2            Northern Oil and Gas, Inc.   \n",
       "3                   Kinder Morgan, Inc.   \n",
       "4    Scripps Networks Interactive, Inc.   \n",
       "..                                  ...   \n",
       "995                 Ingersoll Rand Inc.   \n",
       "996     Phillips Edison & Company, Inc.   \n",
       "997          Press Ganey Holdings, Inc.   \n",
       "998  Esterline Technologies Corporation   \n",
       "999                   FirstEnergy Corp.   \n",
       "\n",
       "                                         componenttext  Rating  \n",
       "0    Some of them have. Some of them are the funded...     0.0  \n",
       "1    So with that, we will go ahead and conclude th...     0.0  \n",
       "2    So on the bonds, obviously, what I said in my ...     1.0  \n",
       "3    I think that they're being cautious about thei...    -1.0  \n",
       "4    Yes, this is Burton. Just to clarify, no, the ...    -1.0  \n",
       "..                                                 ...     ...  \n",
       "995  Sure. Yes. So let me kind of take them in piec...     1.0  \n",
       "996  Sure. Tom, as you know, our current annual div...     0.0  \n",
       "997  Sure, happy to do that. So the nursing perform...     1.0  \n",
       "998  Yes. I think that phasing is very, very import...    -2.0  \n",
       "999  I would say -- I'll give you an example, not s...     1.0  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the second annotator's dataset and rename the column with the annotation\n",
    "rk_annot =pd.read_csv('datasets/RK_1000_datapoints_annotation_set_shuffled.csv')\n",
    "rk_annot = rk_annot.rename(columns={'RK Annotation':'Rating'})\n",
    "rk_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "transcriptcomponentid      int64\n",
       "transcriptid               int64\n",
       "companyid                  int64\n",
       "companyname               object\n",
       "componenttext             object\n",
       "Rating                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the annotation ranking series only contains the datatypes and values that are expected\n",
    "rk_annot.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., -1., -3.,  2.,  3., -2., nan])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the annotation ranking series only contains the datatypes and values that are expected\n",
    "rk_annot['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[376]\n"
     ]
    }
   ],
   "source": [
    "# Determine which row has nan value\n",
    "rows_with_nan = [index for index, row in rk_annot.iterrows() if row.isnull().any()]\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                         1237279\n",
       "transcriptcomponentid                                             69780475\n",
       "transcriptid                                                       1782072\n",
       "companyid                                                        555811978\n",
       "companyname                                 Wyndham Hotels & Resorts, Inc.\n",
       "componenttext            I think as we look at the opportunities that a...\n",
       "Rating                                                                 NaN\n",
       "Name: 376, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rk_annot.loc[376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update row value with annotator rating then recast the series as an int instead of float type\n",
    "rk_annot['Rating'][376] = 2\n",
    "rk_annot['Rating'] = rk_annot['Rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1, -1, -3,  2,  3, -2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-Check to make sure the annotation ranking series only contains the datatypes and values that are expected\n",
    "rk_annot['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Rating', ylabel='count'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generat a histogram of the categoricals from RK's annotations\n",
    "# NOTE: The categoricals skew in the positive direction; also, neutral, or near-neutral ratings are most frequent\n",
    "sns.countplot(rk_annot['Rating'], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>Rating_x</th>\n",
       "      <th>Rating_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332580</td>\n",
       "      <td>21626174</td>\n",
       "      <td>463004</td>\n",
       "      <td>30054660</td>\n",
       "      <td>Ditech Holding Corporation</td>\n",
       "      <td>Some of them have. Some of them are the funded...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439149</td>\n",
       "      <td>29670621</td>\n",
       "      <td>667025</td>\n",
       "      <td>381997</td>\n",
       "      <td>Headwaters Incorporated</td>\n",
       "      <td>So with that, we will go ahead and conclude th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387435</td>\n",
       "      <td>76257909</td>\n",
       "      <td>1943128</td>\n",
       "      <td>30822601</td>\n",
       "      <td>Northern Oil and Gas, Inc.</td>\n",
       "      <td>So on the bonds, obviously, what I said in my ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574255</td>\n",
       "      <td>40819900</td>\n",
       "      <td>961528</td>\n",
       "      <td>34952431</td>\n",
       "      <td>Kinder Morgan, Inc.</td>\n",
       "      <td>I think that they're being cautious about thei...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505727</td>\n",
       "      <td>35203566</td>\n",
       "      <td>809487</td>\n",
       "      <td>6469353</td>\n",
       "      <td>Scripps Networks Interactive, Inc.</td>\n",
       "      <td>Yes, this is Burton. Just to clarify, no, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1473535</td>\n",
       "      <td>82312408</td>\n",
       "      <td>2094667</td>\n",
       "      <td>334158</td>\n",
       "      <td>Ingersoll Rand Inc.</td>\n",
       "      <td>Sure. Yes. So let me kind of take them in piec...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1098188</td>\n",
       "      <td>63457785</td>\n",
       "      <td>1610373</td>\n",
       "      <td>84223462</td>\n",
       "      <td>Phillips Edison &amp; Company, Inc.</td>\n",
       "      <td>Sure. Tom, as you know, our current annual div...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>620056</td>\n",
       "      <td>43058235</td>\n",
       "      <td>1022183</td>\n",
       "      <td>183811756</td>\n",
       "      <td>Press Ganey Holdings, Inc.</td>\n",
       "      <td>Sure, happy to do that. So the nursing perform...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>873979</td>\n",
       "      <td>53941617</td>\n",
       "      <td>1345650</td>\n",
       "      <td>270315</td>\n",
       "      <td>Esterline Technologies Corporation</td>\n",
       "      <td>Yes. I think that phasing is very, very import...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1152329</td>\n",
       "      <td>65639087</td>\n",
       "      <td>1664503</td>\n",
       "      <td>293515</td>\n",
       "      <td>FirstEnergy Corp.</td>\n",
       "      <td>I would say -- I'll give you an example, not s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  transcriptcomponentid  transcriptid  companyid  \\\n",
       "0        332580               21626174        463004   30054660   \n",
       "1        439149               29670621        667025     381997   \n",
       "2       1387435               76257909       1943128   30822601   \n",
       "3        574255               40819900        961528   34952431   \n",
       "4        505727               35203566        809487    6469353   \n",
       "..          ...                    ...           ...        ...   \n",
       "995     1473535               82312408       2094667     334158   \n",
       "996     1098188               63457785       1610373   84223462   \n",
       "997      620056               43058235       1022183  183811756   \n",
       "998      873979               53941617       1345650     270315   \n",
       "999     1152329               65639087       1664503     293515   \n",
       "\n",
       "                            companyname  \\\n",
       "0            Ditech Holding Corporation   \n",
       "1               Headwaters Incorporated   \n",
       "2            Northern Oil and Gas, Inc.   \n",
       "3                   Kinder Morgan, Inc.   \n",
       "4    Scripps Networks Interactive, Inc.   \n",
       "..                                  ...   \n",
       "995                 Ingersoll Rand Inc.   \n",
       "996     Phillips Edison & Company, Inc.   \n",
       "997          Press Ganey Holdings, Inc.   \n",
       "998  Esterline Technologies Corporation   \n",
       "999                   FirstEnergy Corp.   \n",
       "\n",
       "                                         componenttext  Rating_x  Rating_y  \n",
       "0    Some of them have. Some of them are the funded...         0         0  \n",
       "1    So with that, we will go ahead and conclude th...         0         0  \n",
       "2    So on the bonds, obviously, what I said in my ...         2         1  \n",
       "3    I think that they're being cautious about thei...        -1        -1  \n",
       "4    Yes, this is Burton. Just to clarify, no, the ...         2        -1  \n",
       "..                                                 ...       ...       ...  \n",
       "995  Sure. Yes. So let me kind of take them in piec...         1         1  \n",
       "996  Sure. Tom, as you know, our current annual div...         0         0  \n",
       "997  Sure, happy to do that. So the nursing perform...         2         1  \n",
       "998  Yes. I think that phasing is very, very import...        -2        -2  \n",
       "999  I would say -- I'll give you an example, not s...         1         1  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's go about doing some EDA on the two annotation sets, in comparison to one another\n",
    "# We begin by merging the two datasets\n",
    "\n",
    "annot_comb = pd.merge(jdv_annot, rk_annot[['transcriptcomponentid','Rating']],on='transcriptcomponentid', how='left')\n",
    "annot_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some loops to better understand the two annotation series; how are they alike and how do they differ\n",
    "\n",
    "diff_sign = []\n",
    "\n",
    "# This first loop appends each of the entries in which the sign of the first annotator differs from the sign of the second annotator\n",
    "for i in range(len(annot_comb)):\n",
    "    if (np.sign(annot_comb.loc[i]['Rating_x']) == np.sign(annot_comb.loc[i]['Rating_y'])) == False:\n",
    "        diff_sign.append(annot_comb.loc[i])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Instantiate empty lists to be populated by the loops below\n",
    "two_diff = []\n",
    "three_diff = []\n",
    "four_diff = []\n",
    "five_diff = []\n",
    "six_diff = []\n",
    "\n",
    "# By using a series of if, elif statements to populate the just-created empty lists we will produce lists for each of the the categories of\n",
    "# annotation differentials, from two to six\n",
    "\n",
    "for i in range(len(annot_comb)):\n",
    "    if np.absolute((annot_comb.loc[i]['Rating_x'] - annot_comb.loc[i]['Rating_y'])) == 2:\n",
    "        two_diff.append(annot_comb.loc[i])\n",
    "    elif np.absolute((annot_comb.loc[i]['Rating_x'] - annot_comb.loc[i]['Rating_y'])) == 3:\n",
    "        three_diff.append(annot_comb.loc[i])\n",
    "    elif np.absolute((annot_comb.loc[i]['Rating_x'] - annot_comb.loc[i]['Rating_y'])) == 4:\n",
    "        four_diff.append(annot_comb.loc[i])\n",
    "    elif np.absolute((annot_comb.loc[i]['Rating_x'] - annot_comb.loc[i]['Rating_y'])) == 5:\n",
    "        five_diff.append(annot_comb.loc[i])\n",
    "    elif np.absolute((annot_comb.loc[i]['Rating_x'] - annot_comb.loc[i]['Rating_y'])) == 6:\n",
    "        six_diff.append(annot_comb.loc[i])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two cats apart: 116\n",
      "three cats apart: 40\n",
      "four cats apart: 12\n",
      "five cats apart: 2\n",
      "six cats apart: 0\n"
     ]
    }
   ],
   "source": [
    "# Print out the number of entries in each list\n",
    "print('two cats apart:', len(two_diff))\n",
    "print('three cats apart:', len(three_diff))\n",
    "print('four cats apart:', len(four_diff))\n",
    "print('five cats apart:', len(five_diff))\n",
    "print('six cats apart:', len(six_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create CSVs from each list for manual review\n",
    "pd.DataFrame.from_dict(two_diff).to_csv('datasets/review_set/two_diff.csv')\n",
    "pd.DataFrame.from_dict(three_diff).to_csv('datasets/review_set/three_diff.csv')\n",
    "pd.DataFrame.from_dict(four_diff).to_csv('datasets/review_set/four_diff.csv')\n",
    "pd.DataFrame.from_dict(five_diff).to_csv('datasets/review_set/five_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The manual review occurred, for the escalated datapoints, and now the updated annotations need to be imported\n",
    "# Finally, all data needs to be merged and we need to prepare the 'X' and 'y' datasets for the training of our NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSVs into pandas dataframes\n",
    "three_diff_up = pd.read_csv('datasets/review_set/three_diff_jvrk_updated.csv')\n",
    "four_diff_up = pd.read_csv('datasets/review_set/four_diff_jvrk_updated.csv')\n",
    "five_diff_up = pd.read_csv('datasets/review_set/five_diff_jvrk_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the new jointly-rated column on the end\n",
    "three_diff_up.rename(columns = {\"Unnamed: 9\": \"Rating_comb\"}, inplace = True)\n",
    "four_diff_up.rename(columns = {\"Unnamed: 9\": \"Rating_comb\"}, inplace = True)\n",
    "five_diff_up.rename(columns = {\"Unnamed: 9\": \"Rating_comb\"}, inplace = True)\n",
    "\n",
    "# Concatenate the updated annotated sets into one dataframe\n",
    "comb_diff_up = pd.concat([three_diff_up, four_diff_up, five_diff_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to merge all of our rating data into one set so we can clean it and get to a single rating per annotated entry\n",
    "\n",
    "annot_comb_final = pd.merge(annot_comb, comb_diff_up[['transcriptcomponentid','Rating_comb']],right_on='transcriptcomponentid',\n",
    "                            left_on='transcriptcomponentid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There were a total of 54 entries that required escalation and review, so if we count the number of NaN values in the new 'Rating_comb'\n",
    "# column we should find 946 NaN entries, if the previous merges worked correctly\n",
    "annot_comb_final['Rating_comb'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>Rating_x</th>\n",
       "      <th>Rating_y</th>\n",
       "      <th>Rating_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332580</td>\n",
       "      <td>21626174</td>\n",
       "      <td>463004</td>\n",
       "      <td>30054660</td>\n",
       "      <td>Ditech Holding Corporation</td>\n",
       "      <td>Some of them have. Some of them are the funded...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439149</td>\n",
       "      <td>29670621</td>\n",
       "      <td>667025</td>\n",
       "      <td>381997</td>\n",
       "      <td>Headwaters Incorporated</td>\n",
       "      <td>So with that, we will go ahead and conclude th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387435</td>\n",
       "      <td>76257909</td>\n",
       "      <td>1943128</td>\n",
       "      <td>30822601</td>\n",
       "      <td>Northern Oil and Gas, Inc.</td>\n",
       "      <td>So on the bonds, obviously, what I said in my ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574255</td>\n",
       "      <td>40819900</td>\n",
       "      <td>961528</td>\n",
       "      <td>34952431</td>\n",
       "      <td>Kinder Morgan, Inc.</td>\n",
       "      <td>I think that they're being cautious about thei...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505727</td>\n",
       "      <td>35203566</td>\n",
       "      <td>809487</td>\n",
       "      <td>6469353</td>\n",
       "      <td>Scripps Networks Interactive, Inc.</td>\n",
       "      <td>Yes, this is Burton. Just to clarify, no, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>761096</td>\n",
       "      <td>48869751</td>\n",
       "      <td>1188741</td>\n",
       "      <td>368607</td>\n",
       "      <td>Fresh Del Monte Produce Inc.</td>\n",
       "      <td>Jonathan, the Chilean business this year compa...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1501482</td>\n",
       "      <td>83559605</td>\n",
       "      <td>2123382</td>\n",
       "      <td>299081</td>\n",
       "      <td>Dynex Capital, Inc.</td>\n",
       "      <td>Sure. Yes. The implied -- what we're seeing to...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1362486</td>\n",
       "      <td>75137699</td>\n",
       "      <td>1911766</td>\n",
       "      <td>528325</td>\n",
       "      <td>Moody's Corporation</td>\n",
       "      <td>Maybe a big place for me to start is really ju...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1524384</td>\n",
       "      <td>90907348</td>\n",
       "      <td>2382598</td>\n",
       "      <td>112302</td>\n",
       "      <td>AutoNation, Inc.</td>\n",
       "      <td>So it's -- this is Mike Jackson. If I will -- ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1088686</td>\n",
       "      <td>63174107</td>\n",
       "      <td>1601966</td>\n",
       "      <td>275573</td>\n",
       "      <td>National Retail Properties, Inc.</td>\n",
       "      <td>And Spenser, you asked about vacant -- about l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  transcriptcomponentid  transcriptid  companyid  \\\n",
       "0      332580               21626174        463004   30054660   \n",
       "1      439149               29670621        667025     381997   \n",
       "2     1387435               76257909       1943128   30822601   \n",
       "3      574255               40819900        961528   34952431   \n",
       "4      505727               35203566        809487    6469353   \n",
       "5      761096               48869751       1188741     368607   \n",
       "6     1501482               83559605       2123382     299081   \n",
       "7     1362486               75137699       1911766     528325   \n",
       "8     1524384               90907348       2382598     112302   \n",
       "9     1088686               63174107       1601966     275573   \n",
       "\n",
       "                          companyname  \\\n",
       "0          Ditech Holding Corporation   \n",
       "1             Headwaters Incorporated   \n",
       "2          Northern Oil and Gas, Inc.   \n",
       "3                 Kinder Morgan, Inc.   \n",
       "4  Scripps Networks Interactive, Inc.   \n",
       "5        Fresh Del Monte Produce Inc.   \n",
       "6                 Dynex Capital, Inc.   \n",
       "7                 Moody's Corporation   \n",
       "8                    AutoNation, Inc.   \n",
       "9    National Retail Properties, Inc.   \n",
       "\n",
       "                                       componenttext  Rating_x  Rating_y  \\\n",
       "0  Some of them have. Some of them are the funded...         0         0   \n",
       "1  So with that, we will go ahead and conclude th...         0         0   \n",
       "2  So on the bonds, obviously, what I said in my ...         2         1   \n",
       "3  I think that they're being cautious about thei...        -1        -1   \n",
       "4  Yes, this is Burton. Just to clarify, no, the ...         2        -1   \n",
       "5  Jonathan, the Chilean business this year compa...        -1        -3   \n",
       "6  Sure. Yes. The implied -- what we're seeing to...         3         2   \n",
       "7  Maybe a big place for me to start is really ju...         3         2   \n",
       "8  So it's -- this is Mike Jackson. If I will -- ...         1         0   \n",
       "9  And Spenser, you asked about vacant -- about l...         1         0   \n",
       "\n",
       "   Rating_comb  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4         -1.0  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the head and tail of the new dataset\n",
    "annot_comb_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to implement our rating procedures, as outlined in our project write-up\n",
    "\n",
    "# Rule 1: For any entry in which both annotators ratings are two, or fewer, categorical ratings apart (integers ranging from -3 to +3, with 0 inclusive)\n",
    "# we will average the two ratings and round up for positive numbers and down for negative numbers. This, in effect, will help to polarize \n",
    "# the sentiment rankings\n",
    "\n",
    "# Rule 2: For the entries that were reviewed and rated using the escalation procedures, no further edits need to be made, these reflect final ratings\n",
    "\n",
    "Final_Rating = []\n",
    "\n",
    "for i in range(len(annot_comb_final)):\n",
    "    if np.absolute((annot_comb_final.loc[i]['Rating_x'] - annot_comb_final.loc[i]['Rating_y'])) <= 2:\n",
    "        if np.sign((annot_comb_final.loc[i]['Rating_x'] + annot_comb_final.loc[i]['Rating_y'])) == -1:\n",
    "            rating = int(math.floor((annot_comb_final.loc[i]['Rating_x'] + annot_comb_final.loc[i]['Rating_y'])/2))\n",
    "        elif np.sign((annot_comb_final.loc[i]['Rating_x'] + annot_comb_final.loc[i]['Rating_y'])) == 1:\n",
    "            rating = int(math.ceil((annot_comb_final.loc[i]['Rating_x'] + annot_comb_final.loc[i]['Rating_y'])/2))\n",
    "        else:\n",
    "            rating = int(0)\n",
    "    else:\n",
    "        rating = int(annot_comb_final.loc[i]['Rating_comb'])\n",
    "    \n",
    "    Final_Rating.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3, -2, -1,  0,  1,  2,  3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If our previous step worked successfully, seven unique integers should be present in the 'Final_Rating' list we generated\n",
    "np.unique(Final_Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>companyid</th>\n",
       "      <th>companyname</th>\n",
       "      <th>componenttext</th>\n",
       "      <th>Rating_x</th>\n",
       "      <th>Rating_y</th>\n",
       "      <th>Rating_comb</th>\n",
       "      <th>Final_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332580</td>\n",
       "      <td>21626174</td>\n",
       "      <td>463004</td>\n",
       "      <td>30054660</td>\n",
       "      <td>Ditech Holding Corporation</td>\n",
       "      <td>Some of them have. Some of them are the funded...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439149</td>\n",
       "      <td>29670621</td>\n",
       "      <td>667025</td>\n",
       "      <td>381997</td>\n",
       "      <td>Headwaters Incorporated</td>\n",
       "      <td>So with that, we will go ahead and conclude th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387435</td>\n",
       "      <td>76257909</td>\n",
       "      <td>1943128</td>\n",
       "      <td>30822601</td>\n",
       "      <td>Northern Oil and Gas, Inc.</td>\n",
       "      <td>So on the bonds, obviously, what I said in my ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574255</td>\n",
       "      <td>40819900</td>\n",
       "      <td>961528</td>\n",
       "      <td>34952431</td>\n",
       "      <td>Kinder Morgan, Inc.</td>\n",
       "      <td>I think that they're being cautious about thei...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505727</td>\n",
       "      <td>35203566</td>\n",
       "      <td>809487</td>\n",
       "      <td>6469353</td>\n",
       "      <td>Scripps Networks Interactive, Inc.</td>\n",
       "      <td>Yes, this is Burton. Just to clarify, no, the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>761096</td>\n",
       "      <td>48869751</td>\n",
       "      <td>1188741</td>\n",
       "      <td>368607</td>\n",
       "      <td>Fresh Del Monte Produce Inc.</td>\n",
       "      <td>Jonathan, the Chilean business this year compa...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1501482</td>\n",
       "      <td>83559605</td>\n",
       "      <td>2123382</td>\n",
       "      <td>299081</td>\n",
       "      <td>Dynex Capital, Inc.</td>\n",
       "      <td>Sure. Yes. The implied -- what we're seeing to...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1362486</td>\n",
       "      <td>75137699</td>\n",
       "      <td>1911766</td>\n",
       "      <td>528325</td>\n",
       "      <td>Moody's Corporation</td>\n",
       "      <td>Maybe a big place for me to start is really ju...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1524384</td>\n",
       "      <td>90907348</td>\n",
       "      <td>2382598</td>\n",
       "      <td>112302</td>\n",
       "      <td>AutoNation, Inc.</td>\n",
       "      <td>So it's -- this is Mike Jackson. If I will -- ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1088686</td>\n",
       "      <td>63174107</td>\n",
       "      <td>1601966</td>\n",
       "      <td>275573</td>\n",
       "      <td>National Retail Properties, Inc.</td>\n",
       "      <td>And Spenser, you asked about vacant -- about l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>615935</td>\n",
       "      <td>42974545</td>\n",
       "      <td>1020026</td>\n",
       "      <td>388763</td>\n",
       "      <td>Enterprise Products Partners L.P.</td>\n",
       "      <td>This is R.B. The facility's operating very wel...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>948590</td>\n",
       "      <td>57333057</td>\n",
       "      <td>1440969</td>\n",
       "      <td>25981</td>\n",
       "      <td>Callaway Golf Company</td>\n",
       "      <td>I do, and the only reason I hedge that a littl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>371272</td>\n",
       "      <td>24707586</td>\n",
       "      <td>539208</td>\n",
       "      <td>34074951</td>\n",
       "      <td>Noranda Aluminum Holding Corporation</td>\n",
       "      <td>We should think about it as being more front-e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>755934</td>\n",
       "      <td>48718823</td>\n",
       "      <td>1184468</td>\n",
       "      <td>267906</td>\n",
       "      <td>Duke Realty Corporation</td>\n",
       "      <td>I think it's a combination of a little bit of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>993754</td>\n",
       "      <td>60047302</td>\n",
       "      <td>1518412</td>\n",
       "      <td>401541</td>\n",
       "      <td>Lennox International Inc.</td>\n",
       "      <td>Our HVAC business was down just because of lum...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1497907</td>\n",
       "      <td>84793913</td>\n",
       "      <td>2158148</td>\n",
       "      <td>168569</td>\n",
       "      <td>American Airlines Group Inc.</td>\n",
       "      <td>It is something we would consider as we look o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>507957</td>\n",
       "      <td>35484223</td>\n",
       "      <td>817983</td>\n",
       "      <td>251230</td>\n",
       "      <td>Applied Materials, Inc.</td>\n",
       "      <td>Inflections in the DRAM business going forward...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>150871</td>\n",
       "      <td>13221431</td>\n",
       "      <td>265391</td>\n",
       "      <td>391396</td>\n",
       "      <td>EXCO Resources, Inc.</td>\n",
       "      <td>Yes, we haven't done it, but we're sure prepar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52419</td>\n",
       "      <td>8208068</td>\n",
       "      <td>124064</td>\n",
       "      <td>192089</td>\n",
       "      <td>YRC Worldwide Inc.</td>\n",
       "      <td>I think you're right, Tom. It's all of the abo...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>121646</td>\n",
       "      <td>12433427</td>\n",
       "      <td>211971</td>\n",
       "      <td>94728</td>\n",
       "      <td>Teradyne, Inc.</td>\n",
       "      <td>Yes, it was. The $28 million is under our watc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  transcriptcomponentid  transcriptid  companyid  \\\n",
       "0       332580               21626174        463004   30054660   \n",
       "1       439149               29670621        667025     381997   \n",
       "2      1387435               76257909       1943128   30822601   \n",
       "3       574255               40819900        961528   34952431   \n",
       "4       505727               35203566        809487    6469353   \n",
       "5       761096               48869751       1188741     368607   \n",
       "6      1501482               83559605       2123382     299081   \n",
       "7      1362486               75137699       1911766     528325   \n",
       "8      1524384               90907348       2382598     112302   \n",
       "9      1088686               63174107       1601966     275573   \n",
       "10      615935               42974545       1020026     388763   \n",
       "11      948590               57333057       1440969      25981   \n",
       "12      371272               24707586        539208   34074951   \n",
       "13      755934               48718823       1184468     267906   \n",
       "14      993754               60047302       1518412     401541   \n",
       "15     1497907               84793913       2158148     168569   \n",
       "16      507957               35484223        817983     251230   \n",
       "17      150871               13221431        265391     391396   \n",
       "18       52419                8208068        124064     192089   \n",
       "19      121646               12433427        211971      94728   \n",
       "\n",
       "                             companyname  \\\n",
       "0             Ditech Holding Corporation   \n",
       "1                Headwaters Incorporated   \n",
       "2             Northern Oil and Gas, Inc.   \n",
       "3                    Kinder Morgan, Inc.   \n",
       "4     Scripps Networks Interactive, Inc.   \n",
       "5           Fresh Del Monte Produce Inc.   \n",
       "6                    Dynex Capital, Inc.   \n",
       "7                    Moody's Corporation   \n",
       "8                       AutoNation, Inc.   \n",
       "9       National Retail Properties, Inc.   \n",
       "10     Enterprise Products Partners L.P.   \n",
       "11                 Callaway Golf Company   \n",
       "12  Noranda Aluminum Holding Corporation   \n",
       "13               Duke Realty Corporation   \n",
       "14             Lennox International Inc.   \n",
       "15          American Airlines Group Inc.   \n",
       "16               Applied Materials, Inc.   \n",
       "17                  EXCO Resources, Inc.   \n",
       "18                    YRC Worldwide Inc.   \n",
       "19                        Teradyne, Inc.   \n",
       "\n",
       "                                        componenttext  Rating_x  Rating_y  \\\n",
       "0   Some of them have. Some of them are the funded...         0         0   \n",
       "1   So with that, we will go ahead and conclude th...         0         0   \n",
       "2   So on the bonds, obviously, what I said in my ...         2         1   \n",
       "3   I think that they're being cautious about thei...        -1        -1   \n",
       "4   Yes, this is Burton. Just to clarify, no, the ...         2        -1   \n",
       "5   Jonathan, the Chilean business this year compa...        -1        -3   \n",
       "6   Sure. Yes. The implied -- what we're seeing to...         3         2   \n",
       "7   Maybe a big place for me to start is really ju...         3         2   \n",
       "8   So it's -- this is Mike Jackson. If I will -- ...         1         0   \n",
       "9   And Spenser, you asked about vacant -- about l...         1         0   \n",
       "10  This is R.B. The facility's operating very wel...        -1         0   \n",
       "11  I do, and the only reason I hedge that a littl...         1         1   \n",
       "12  We should think about it as being more front-e...         0         0   \n",
       "13  I think it's a combination of a little bit of ...         1        -1   \n",
       "14  Our HVAC business was down just because of lum...         2         1   \n",
       "15  It is something we would consider as we look o...         0         0   \n",
       "16  Inflections in the DRAM business going forward...         1         1   \n",
       "17  Yes, we haven't done it, but we're sure prepar...         1         0   \n",
       "18  I think you're right, Tom. It's all of the abo...         1        -1   \n",
       "19  Yes, it was. The $28 million is under our watc...         1         1   \n",
       "\n",
       "    Rating_comb  Final_Rating  \n",
       "0           NaN             0  \n",
       "1           NaN             0  \n",
       "2           NaN             2  \n",
       "3           NaN            -1  \n",
       "4          -1.0            -1  \n",
       "5           NaN            -2  \n",
       "6           NaN             3  \n",
       "7           NaN             3  \n",
       "8           NaN             1  \n",
       "9           NaN             1  \n",
       "10          NaN            -1  \n",
       "11          NaN             1  \n",
       "12          NaN             0  \n",
       "13          NaN             0  \n",
       "14          NaN             2  \n",
       "15          NaN             0  \n",
       "16          NaN             1  \n",
       "17          NaN             1  \n",
       "18          NaN             0  \n",
       "19          NaN             1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now append the new list to the dataframe used to generate the ratings\n",
    "annot_comb_final['Final_Rating'] = Final_Rating\n",
    "annot_comb_final[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This BERT Model does not work with classifier values less than zero; we will use a dict to map our Annotation IDs to positive values for the purposes\n",
    "# of fitting the model\n",
    "mapping_dict = {-3:0, -2:1, -1:2, 0:3, 1:4, 2:5, 3:6}\n",
    "annot_comb_final['Final_Rating'].replace(mapping_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train, validation and test datasets for the model to be fit below\n",
    "\n",
    "X = annot_comb_final.componenttext.values\n",
    "y = annot_comb_final['Final_Rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=3) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train, val and test data\n",
    "all_data = np.concatenate([X_train, X_val, X_test])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_text = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  \n",
      " Some of them have. Some of them are the funded loans that are on the balance sheet held for sale and some of them are pipeline loans that haven't closed yet. So it would not be inclusive of the expenses to be incurred for closing. \n",
      "\n",
      "Token IDs:  \n",
      " [101, 2070, 1997, 2068, 2031, 1012, 2070, 1997, 2068, 2024, 1996, 6787, 10940, 2008, 2024, 2006, 1996, 5703, 7123, 2218, 2005, 5096, 1998, 2070, 1997, 2068, 2024, 13117, 10940, 2008, 4033, 1005, 1056, 2701, 2664, 1012, 2061, 2009, 2052, 2025, 2022, 18678, 1997, 1996, 11727, 2000, 2022, 22667, 2005, 5494, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "Convert IDs tok Tokens:  \n",
      " ['[CLS]', 'some', 'of', 'them', 'have', '.', 'some', 'of', 'them', 'are', 'the', 'funded', 'loans', 'that', 'are', 'on', 'the', 'balance', 'sheet', 'held', 'for', 'sale', 'and', 'some', 'of', 'them', 'are', 'pipeline', 'loans', 'that', 'haven', \"'\", 't', 'closed', 'yet', '.', 'so', 'it', 'would', 'not', 'be', 'inclusive', 'of', 'the', 'expenses', 'to', 'be', 'incurred', 'for', 'closing', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
      "\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', '\\n', X[0], '\\n')\n",
    "print('Token IDs: ', '\\n', token_ids, '\\n')\n",
    "print('Convert IDs tok Tokens: ', '\\n', tokenizer.convert_ids_to_tokens(token_ids), '\\n' )\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed.\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Check to ensure that each of the classification categories are represented in our train, validation and test datasets\n",
    "# by viewing the unique values in each dataset, which should align\n",
    "print(np.unique(y_train))\n",
    "print(np.unique(y_val))\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   1.810796   |     -      |     -     |   3.52   \n",
      "   1    |   37    |   1.799475   |     -      |     -     |   2.80   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   1.805731   |  1.647578  |   37.50   |   6.84   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   1.647735   |     -      |     -     |   3.53   \n",
      "   2    |   37    |   1.564434   |     -      |     -     |   2.80   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   1.610469   |  1.562445  |   39.90   |   6.84   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   20    |   1.399979   |     -      |     -     |   3.52   \n",
      "   3    |   37    |   1.323106   |     -      |     -     |   2.80   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   1.365588   |  1.475553  |   40.38   |   6.84   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   20    |   1.202856   |     -      |     -     |   3.55   \n",
      "   4    |   37    |   1.095805   |     -      |     -     |   2.87   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   1.154965   |  1.441678  |   45.19   |   6.94   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# By adding this first line of code to our executables, we can derive more detailed error messages if issues arise with the GPU\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Initialize the BERTClassifier model and run two epochs on the training data\n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run BERT, but this time mapping to only 3 categories, pos, neg and neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_comb_final['Final_Rating'] = Final_Rating\n",
    "mapping_dict = {-3:0, -2:0, -1:1, 0:1, 1:1, 2:2, 3:2}\n",
    "annot_comb_final['Final_Rating'].replace(mapping_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train, validation and test datasets for the model to be fit below\n",
    "\n",
    "X = annot_comb_final.componenttext.values\n",
    "y = annot_comb_final['Final_Rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=3) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train, val and test data\n",
    "all_data = np.concatenate([X_train, X_val, X_test])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_text = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  \n",
      " Some of them have. Some of them are the funded loans that are on the balance sheet held for sale and some of them are pipeline loans that haven't closed yet. So it would not be inclusive of the expenses to be incurred for closing. \n",
      "\n",
      "Token IDs:  \n",
      " [101, 2070, 1997, 2068, 2031, 1012, 2070, 1997, 2068, 2024, 1996, 6787, 10940, 2008, 2024, 2006, 1996, 5703, 7123, 2218, 2005, 5096, 1998, 2070, 1997, 2068, 2024, 13117, 10940, 2008, 4033, 1005, 1056, 2701, 2664, 1012, 2061, 2009, 2052, 2025, 2022, 18678, 1997, 1996, 11727, 2000, 2022, 22667, 2005, 5494, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "Convert IDs tok Tokens:  \n",
      " ['[CLS]', 'some', 'of', 'them', 'have', '.', 'some', 'of', 'them', 'are', 'the', 'funded', 'loans', 'that', 'are', 'on', 'the', 'balance', 'sheet', 'held', 'for', 'sale', 'and', 'some', 'of', 'them', 'are', 'pipeline', 'loans', 'that', 'haven', \"'\", 't', 'closed', 'yet', '.', 'so', 'it', 'would', 'not', 'be', 'inclusive', 'of', 'the', 'expenses', 'to', 'be', 'incurred', 'for', 'closing', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
      "\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', '\\n', X[0], '\\n')\n",
    "print('Token IDs: ', '\\n', token_ids, '\\n')\n",
    "print('Convert IDs tok Tokens: ', '\\n', tokenizer.convert_ids_to_tokens(token_ids), '\\n' )\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed.\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Check to ensure that each of the classification categories are represented in our train, validation and test datasets\n",
    "# by viewing the unique values in each dataset, which should align\n",
    "print(np.unique(y_train))\n",
    "print(np.unique(y_val))\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to clear GPU cache before running model\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "#del variables\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   1.336444   |     -      |     -     |   3.57   \n",
      "   1    |   37    |   1.036352   |     -      |     -     |   2.82   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   1.202192   |  0.964442  |   58.17   |   6.91   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.994932   |     -      |     -     |   3.53   \n",
      "   2    |   37    |   0.890661   |     -      |     -     |   2.81   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.948285   |  0.840566  |   67.31   |   6.85   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   20    |   0.752251   |     -      |     -     |   3.54   \n",
      "   3    |   37    |   0.646189   |     -      |     -     |   2.80   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.704802   |  0.876024  |   67.31   |   6.86   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   20    |   0.524144   |     -      |     -     |   3.53   \n",
      "   4    |   37    |   0.490070   |     -      |     -     |   2.82   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.508900   |  0.862199  |   67.31   |   6.86   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# By adding this first line of code to our executables, we can derive more detailed error messages if issues arise with the GPU\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# Initialize the BERTClassifier model and run two epochs on the training data\n",
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  77]\n",
      " [  1 331]\n",
      " [  2 192]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
